{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16be37e2-a808-4560-8751-34e5d0154f53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from IPython.display import display\n",
    "import math\n",
    "import os\n",
    "import gc\n",
    "import lightgbm as lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "038f88c8-b40f-4bcc-bd88-8cfdbbdbb3a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def augment(data, label):\n",
    "    assert len(data) == len(label)\n",
    "    def get_map(num_p, wind_p):\n",
    "        conv = [0]*34\n",
    "        inv = [0]*34\n",
    "        for i, p in enumerate(num_p):\n",
    "            for k in range(9):\n",
    "                conv[i*9+k] = p*9+k\n",
    "                inv[p*9+k] = i*9+k\n",
    "        for k in range(27, 31):\n",
    "            conv[k] = k\n",
    "            inv[k] = k\n",
    "        for k in range(3):\n",
    "            conv[31+(k+wind_p)%3] = 31+k\n",
    "            inv[31+(k-wind_p)%3] = 31+k\n",
    "        return np.array(conv, dtype=np.uint8), np.array(inv, dtype=np.uint8)\n",
    "    \n",
    "    data_columns = data.columns\n",
    "    label_columns = label.columns\n",
    "    \n",
    "    data = data.to_numpy()\n",
    "    label = label.to_numpy()\n",
    "    \n",
    "    rows = len(data)\n",
    "    augmented_data = np.empty((rows*18, 20), dtype=np.uint8)\n",
    "    augmented_label = np.empty((rows*18, 34), dtype=np.uint8)\n",
    "    \n",
    "    k = 0\n",
    "    for num_p in itertools.permutations(range(3)):\n",
    "        for wind_p in range(3):\n",
    "            conv, inv = get_map(num_p, wind_p)\n",
    "            conv = np.concatenate(([0], conv+1))\n",
    "            augmented_data[k:k+rows] = conv[data]\n",
    "            augmented_label[k:k+rows] = label[:,inv]\n",
    "            k += rows\n",
    "    augmented_data = pd.DataFrame(augmented_data, columns=data_columns)\n",
    "    augmented_label = pd.DataFrame(augmented_label, columns=label_columns)\n",
    "    return augmented_data, augmented_label\n",
    "\n",
    "def featurize(data):\n",
    "    TILE_NAME = [f'{i+1}萬' for i in range(9)] + [f'{i+1}筒' for i in range(9)] + [f'{i+1}索' for i in range(9)] + list('東南西北白発中')\n",
    "    FEATURE_NAME = [f'捨牌{i+1}' for i in range(20)] + [f'リーチ前{i}' for i in range(20)] + [f'{t}捨てカウント' for t in TILE_NAME]\n",
    "    \n",
    "    \n",
    "    data = data.to_numpy()\n",
    "    res = np.empty((len(data), 20+20+34), np.uint8)\n",
    "    res[:,:20] = data\n",
    "    temp = data[:,::-1]\n",
    "    shifts = np.argmax(temp!=0, axis=1)\n",
    "    shifts = np.arange(20)[np.newaxis, :] + shifts[:, np.newaxis]\n",
    "    shifts[shifts>=20] = 0\n",
    "    res[:, 20:40] = temp[np.arange(data.shape[0])[:, np.newaxis], shifts]\n",
    "    for k in range(34):\n",
    "        res[:,40+k] = np.sum(temp==k+1, axis=1)\n",
    "    return pd.DataFrame(res, columns=FEATURE_NAME)\n",
    "\n",
    "def prepare_data(src_path='data/ver1.feather', dst_dir='data/', portion=1, augment_flag=True, featurize_flag=True):\n",
    "    \n",
    "    def helper(path, data, augment_flag):\n",
    "        data.reset_index(drop=True, inplace=True)\n",
    "        data, label = data[data.columns[:20]], data[data.columns[20:]]\n",
    "        if augment_flag:\n",
    "            data, label = augment(data, label)\n",
    "        if featurize_flag:\n",
    "            data = featurize(data)\n",
    "        data.to_feather(f'{path}-data.feather')\n",
    "        label.to_feather(f'{path}-label.feather')\n",
    "\n",
    "    os.makedirs(dst_dir, exist_ok=True)\n",
    "    raw = pd.read_feather(src_path)\n",
    "    if portion < 1:\n",
    "        raw = raw[:round(len(raw)*portion)]\n",
    "    s1 = round(len(raw)*0.8)\n",
    "    s2 = round(len(raw)*0.9)\n",
    "    train = raw[:s1]\n",
    "    validation = raw[s1:s2]\n",
    "    test = raw[s2:]\n",
    "    \n",
    "    print('Train Data')\n",
    "    helper(os.path.join(dst_dir, 'train'), train, augment_flag)\n",
    "    print('Validation Data')\n",
    "    helper(os.path.join(dst_dir, 'validation'), validation, False)\n",
    "    print('Test Data')\n",
    "    helper(os.path.join(dst_dir, 'test'), test, False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "457f1989-1518-42e0-949c-ae47aab6fa3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data\n",
      "Validation Data\n",
      "Test Data\n"
     ]
    }
   ],
   "source": [
    "# prepare_data(dst_dir='data/vanilla/', augment_flag=False, featurize_flag=False)\n",
    "# prepare_data(dst_dir='data/augmented/', augment_flag=True, featurize_flag=False)\n",
    "# prepare_data(dst_dir='data/featurized/', augment_flag=False, featurize_flag=True)\n",
    "# prepare_data(dst_dir='data/both/', augment_flag=True, featurize_flag=True)\n",
    "prepare_data(dst_dir='data/light/', augment_flag=True, featurize_flag=True, portion=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a020d7d4-708f-449d-b373-1ca63113c230",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "TILES = [f'{i+1}萬' for i in range(9)] + list('東南西北白')\n",
    "WAITS = [f'{t}待' for t in TILES]\n",
    "\n",
    "def train_and_test(data_dir, **train_params):\n",
    "    \n",
    "    models = {}\n",
    "    if 'params' in train_params:\n",
    "        pp = train_params['params']\n",
    "        del train_params['params']\n",
    "    else:\n",
    "        pp = {}\n",
    "    \n",
    "    \n",
    "    td = pd.read_feather(os.path.join(data_dir, 'train-data.feather'))\n",
    "    vd = pd.read_feather(os.path.join(data_dir, 'validation-data.feather'))\n",
    "    tl = pd.read_feather(os.path.join(data_dir, 'train-label.feather'))\n",
    "    vl = pd.read_feather(os.path.join(data_dir, 'validation-label.feather'))\n",
    "    gc.collect()\n",
    "    \n",
    "    if 'リーチ前0' in td:\n",
    "        categoricals = [f'捨牌{i+1}' for i in range(20)] + [f'リーチ前{i}' for i in range(20)]\n",
    "    else:\n",
    "        categoricals = [f'捨牌{i+1}' for i in range(20)]\n",
    "    \n",
    "#     for tile in itertools.chain(range(9), range(27,32)):\n",
    "    for tile in ['5萬待']:\n",
    "        train_dataset = lg.Dataset(td, label=tl[tile])\n",
    "        valid_dataset = lg.Dataset(vd, label=vl[tile])\n",
    "        gc.collect()\n",
    "        params = {\n",
    "            'two_round': True,\n",
    "            'use_missing': False,\n",
    "            'objective': 'binary',}\n",
    "        params.update(pp)\n",
    "        model = lg.train(train_set=train_dataset,\n",
    "                         valid_sets=[valid_dataset],\n",
    "                         categorical_feature=categoricals,\n",
    "                         params=params,\n",
    "                         **train_params)\n",
    "        display(model.trees_to_dataframe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4d6cafd8-1d28-4078-9c5a-b91cee404418",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hahho\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\basic.py:1705: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['リーチ前0', 'リーチ前1', 'リーチ前10', 'リーチ前11', 'リーチ前12', 'リーチ前13', 'リーチ前14', 'リーチ前15', 'リーチ前16', 'リーチ前17', 'リーチ前18', 'リーチ前19', 'リーチ前2', 'リーチ前3', 'リーチ前4', 'リーチ前5', 'リーチ前6', 'リーチ前7', 'リーチ前8', 'リーチ前9', '捨牌1', '捨牌10', '捨牌11', '捨牌12', '捨牌13', '捨牌14', '捨牌15', '捨牌16', '捨牌17', '捨牌18', '捨牌19', '捨牌2', '捨牌20', '捨牌3', '捨牌4', '捨牌5', '捨牌6', '捨牌7', '捨牌8', '捨牌9']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2837988, number of negative: 31335804\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 4.227917 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1390\n",
      "[LightGBM] [Info] Number of data points in the train set: 34173792, number of used features: 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hahho\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "c:\\users\\hahho\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.083046 -> initscore=-2.401666\n",
      "[LightGBM] [Info] Start training from score -2.401666\n",
      "[1]\tvalid_0's binary_logloss: 0.283305\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "0.1\n",
      "[2]\tvalid_0's binary_logloss: 0.281501\n",
      "0.1\n",
      "[3]\tvalid_0's binary_logloss: 0.279934\n",
      "0.1\n",
      "[4]\tvalid_0's binary_logloss: 0.278588\n",
      "0.1\n",
      "[5]\tvalid_0's binary_logloss: 0.277451\n",
      "0.1\n",
      "[6]\tvalid_0's binary_logloss: 0.276449\n",
      "0.1\n",
      "[7]\tvalid_0's binary_logloss: 0.275586\n",
      "0.1\n",
      "[8]\tvalid_0's binary_logloss: 0.274828\n",
      "0.1\n",
      "[9]\tvalid_0's binary_logloss: 0.274166\n",
      "0.1\n",
      "[10]\tvalid_0's binary_logloss: 0.273578\n",
      "0.1\n",
      "[11]\tvalid_0's binary_logloss: 0.273067\n",
      "0.1\n",
      "[12]\tvalid_0's binary_logloss: 0.272592\n",
      "0.1\n",
      "[13]\tvalid_0's binary_logloss: 0.272187\n",
      "0.1\n",
      "[14]\tvalid_0's binary_logloss: 0.271824\n",
      "0.1\n",
      "[15]\tvalid_0's binary_logloss: 0.271504\n",
      "0.1\n",
      "[16]\tvalid_0's binary_logloss: 0.271204\n",
      "0.1\n",
      "[17]\tvalid_0's binary_logloss: 0.270943\n",
      "0.1\n",
      "[18]\tvalid_0's binary_logloss: 0.270709\n",
      "0.1\n",
      "[19]\tvalid_0's binary_logloss: 0.270483\n",
      "0.1\n",
      "[20]\tvalid_0's binary_logloss: 0.270293\n",
      "0.1\n",
      "[21]\tvalid_0's binary_logloss: 0.270132\n",
      "0.1\n",
      "[22]\tvalid_0's binary_logloss: 0.269979\n",
      "0.1\n",
      "[23]\tvalid_0's binary_logloss: 0.269842\n",
      "0.1\n",
      "[24]\tvalid_0's binary_logloss: 0.269708\n",
      "0.1\n",
      "[25]\tvalid_0's binary_logloss: 0.269582\n",
      "0.1\n",
      "[26]\tvalid_0's binary_logloss: 0.269474\n",
      "0.1\n",
      "[27]\tvalid_0's binary_logloss: 0.26938\n",
      "0.1\n",
      "[28]\tvalid_0's binary_logloss: 0.269294\n",
      "0.1\n",
      "[29]\tvalid_0's binary_logloss: 0.269195\n",
      "0.1\n",
      "[30]\tvalid_0's binary_logloss: 0.269125\n",
      "0.1\n",
      "[31]\tvalid_0's binary_logloss: 0.269063\n",
      "0.1\n",
      "[32]\tvalid_0's binary_logloss: 0.269004\n",
      "0.1\n",
      "[33]\tvalid_0's binary_logloss: 0.268935\n",
      "0.1\n",
      "[34]\tvalid_0's binary_logloss: 0.268884\n",
      "0.1\n",
      "[35]\tvalid_0's binary_logloss: 0.268844\n",
      "0.1\n",
      "[36]\tvalid_0's binary_logloss: 0.268811\n",
      "0.1\n",
      "[37]\tvalid_0's binary_logloss: 0.268782\n",
      "0.1\n",
      "[38]\tvalid_0's binary_logloss: 0.268731\n",
      "0.1\n",
      "[39]\tvalid_0's binary_logloss: 0.268705\n",
      "0.1\n",
      "[40]\tvalid_0's binary_logloss: 0.268681\n",
      "0.1\n",
      "[41]\tvalid_0's binary_logloss: 0.26866\n",
      "0.1\n",
      "[42]\tvalid_0's binary_logloss: 0.268644\n",
      "0.1\n",
      "[43]\tvalid_0's binary_logloss: 0.268628\n",
      "0.1\n",
      "[44]\tvalid_0's binary_logloss: 0.268589\n",
      "0.1\n",
      "[45]\tvalid_0's binary_logloss: 0.268542\n",
      "0.1\n",
      "[46]\tvalid_0's binary_logloss: 0.268533\n",
      "0.1\n",
      "[47]\tvalid_0's binary_logloss: 0.26851\n",
      "0.1\n",
      "[48]\tvalid_0's binary_logloss: 0.268499\n",
      "0.1\n",
      "[49]\tvalid_0's binary_logloss: 0.268527\n",
      "0.1\n",
      "[50]\tvalid_0's binary_logloss: 0.268507\n",
      "0.05\n",
      "[51]\tvalid_0's binary_logloss: 0.26849\n",
      "0.05\n",
      "[52]\tvalid_0's binary_logloss: 0.268485\n",
      "0.05\n",
      "[53]\tvalid_0's binary_logloss: 0.268479\n",
      "0.05\n",
      "[54]\tvalid_0's binary_logloss: 0.268496\n",
      "0.05\n",
      "[55]\tvalid_0's binary_logloss: 0.268483\n",
      "0.05\n",
      "[56]\tvalid_0's binary_logloss: 0.26848\n",
      "0.05\n",
      "[57]\tvalid_0's binary_logloss: 0.268474\n",
      "0.05\n",
      "[58]\tvalid_0's binary_logloss: 0.268475\n",
      "0.05\n",
      "[59]\tvalid_0's binary_logloss: 0.268471\n",
      "0.05\n",
      "[60]\tvalid_0's binary_logloss: 0.268462\n",
      "0.05\n",
      "[61]\tvalid_0's binary_logloss: 0.268449\n",
      "0.05\n",
      "[62]\tvalid_0's binary_logloss: 0.268448\n",
      "0.05\n",
      "[63]\tvalid_0's binary_logloss: 0.268447\n",
      "0.05\n",
      "[64]\tvalid_0's binary_logloss: 0.268442\n",
      "0.05\n",
      "[65]\tvalid_0's binary_logloss: 0.268437\n",
      "0.05\n",
      "[66]\tvalid_0's binary_logloss: 0.268431\n",
      "0.05\n",
      "[67]\tvalid_0's binary_logloss: 0.268425\n",
      "0.05\n",
      "[68]\tvalid_0's binary_logloss: 0.268421\n",
      "0.05\n",
      "[69]\tvalid_0's binary_logloss: 0.268412\n",
      "0.05\n",
      "[70]\tvalid_0's binary_logloss: 0.268409\n",
      "0.05\n",
      "[71]\tvalid_0's binary_logloss: 0.268402\n",
      "0.05\n",
      "[72]\tvalid_0's binary_logloss: 0.2684\n",
      "0.05\n",
      "[73]\tvalid_0's binary_logloss: 0.268392\n",
      "0.05\n",
      "[74]\tvalid_0's binary_logloss: 0.268387\n",
      "0.05\n",
      "[75]\tvalid_0's binary_logloss: 0.268383\n",
      "0.05\n",
      "[76]\tvalid_0's binary_logloss: 0.268381\n",
      "0.05\n",
      "[77]\tvalid_0's binary_logloss: 0.26838\n",
      "0.05\n",
      "[78]\tvalid_0's binary_logloss: 0.268397\n",
      "0.05\n",
      "[79]\tvalid_0's binary_logloss: 0.268393\n",
      "0.05\n",
      "[80]\tvalid_0's binary_logloss: 0.268393\n",
      "0.05\n",
      "[81]\tvalid_0's binary_logloss: 0.26839\n",
      "0.05\n",
      "[82]\tvalid_0's binary_logloss: 0.268389\n",
      "0.05\n",
      "[83]\tvalid_0's binary_logloss: 0.268385\n",
      "0.05\n",
      "[84]\tvalid_0's binary_logloss: 0.268381\n",
      "0.05\n",
      "[85]\tvalid_0's binary_logloss: 0.26837\n",
      "0.05\n",
      "[86]\tvalid_0's binary_logloss: 0.268364\n",
      "0.05\n",
      "[87]\tvalid_0's binary_logloss: 0.268361\n",
      "0.05\n",
      "[88]\tvalid_0's binary_logloss: 0.268359\n",
      "0.05\n",
      "[89]\tvalid_0's binary_logloss: 0.26836\n",
      "0.05\n",
      "[90]\tvalid_0's binary_logloss: 0.268356\n",
      "0.05\n",
      "[91]\tvalid_0's binary_logloss: 0.268345\n",
      "0.05\n",
      "[92]\tvalid_0's binary_logloss: 0.26834\n",
      "0.05\n",
      "[93]\tvalid_0's binary_logloss: 0.268339\n",
      "0.05\n",
      "[94]\tvalid_0's binary_logloss: 0.268334\n",
      "0.05\n",
      "[95]\tvalid_0's binary_logloss: 0.26833\n",
      "0.05\n",
      "[96]\tvalid_0's binary_logloss: 0.268325\n",
      "0.05\n",
      "[97]\tvalid_0's binary_logloss: 0.268323\n",
      "0.05\n",
      "[98]\tvalid_0's binary_logloss: 0.26832\n",
      "0.05\n",
      "[99]\tvalid_0's binary_logloss: 0.26832\n",
      "0.05\n",
      "[100]\tvalid_0's binary_logloss: 0.268316\n",
      "0.03333333333333333\n",
      "[101]\tvalid_0's binary_logloss: 0.268312\n",
      "0.03333333333333333\n",
      "[102]\tvalid_0's binary_logloss: 0.268308\n",
      "0.03333333333333333\n",
      "[103]\tvalid_0's binary_logloss: 0.268307\n",
      "0.03333333333333333\n",
      "[104]\tvalid_0's binary_logloss: 0.268305\n",
      "0.03333333333333333\n",
      "[105]\tvalid_0's binary_logloss: 0.268303\n",
      "0.03333333333333333\n",
      "[106]\tvalid_0's binary_logloss: 0.268303\n",
      "0.03333333333333333\n",
      "[107]\tvalid_0's binary_logloss: 0.268301\n",
      "0.03333333333333333\n",
      "[108]\tvalid_0's binary_logloss: 0.268301\n",
      "0.03333333333333333\n",
      "[109]\tvalid_0's binary_logloss: 0.268299\n",
      "0.03333333333333333\n",
      "[110]\tvalid_0's binary_logloss: 0.268294\n",
      "0.03333333333333333\n",
      "[111]\tvalid_0's binary_logloss: 0.268293\n",
      "0.03333333333333333\n",
      "[112]\tvalid_0's binary_logloss: 0.268292\n",
      "0.03333333333333333\n",
      "[113]\tvalid_0's binary_logloss: 0.268287\n",
      "0.03333333333333333\n",
      "[114]\tvalid_0's binary_logloss: 0.268286\n",
      "0.03333333333333333\n",
      "[115]\tvalid_0's binary_logloss: 0.268284\n",
      "0.03333333333333333\n",
      "[116]\tvalid_0's binary_logloss: 0.268282\n",
      "0.03333333333333333\n",
      "[117]\tvalid_0's binary_logloss: 0.268281\n",
      "0.03333333333333333\n",
      "[118]\tvalid_0's binary_logloss: 0.268281\n",
      "0.03333333333333333\n",
      "[119]\tvalid_0's binary_logloss: 0.26828\n",
      "0.03333333333333333\n",
      "[120]\tvalid_0's binary_logloss: 0.268277\n",
      "0.03333333333333333\n",
      "[121]\tvalid_0's binary_logloss: 0.268276\n",
      "0.03333333333333333\n",
      "[122]\tvalid_0's binary_logloss: 0.268276\n",
      "0.03333333333333333\n",
      "[123]\tvalid_0's binary_logloss: 0.268275\n",
      "0.03333333333333333\n",
      "[124]\tvalid_0's binary_logloss: 0.268269\n",
      "0.03333333333333333\n",
      "[125]\tvalid_0's binary_logloss: 0.268269\n",
      "0.03333333333333333\n",
      "[126]\tvalid_0's binary_logloss: 0.268267\n",
      "0.03333333333333333\n",
      "[127]\tvalid_0's binary_logloss: 0.268301\n",
      "0.03333333333333333\n",
      "[128]\tvalid_0's binary_logloss: 0.268298\n",
      "0.03333333333333333\n",
      "[129]\tvalid_0's binary_logloss: 0.268297\n",
      "0.03333333333333333\n",
      "[130]\tvalid_0's binary_logloss: 0.268297\n",
      "0.03333333333333333\n",
      "[131]\tvalid_0's binary_logloss: 0.268297\n",
      "0.03333333333333333\n",
      "[132]\tvalid_0's binary_logloss: 0.268296\n",
      "0.03333333333333333\n",
      "[133]\tvalid_0's binary_logloss: 0.268296\n",
      "0.03333333333333333\n",
      "[134]\tvalid_0's binary_logloss: 0.268295\n",
      "0.03333333333333333\n",
      "[135]\tvalid_0's binary_logloss: 0.268292\n",
      "0.03333333333333333\n",
      "[136]\tvalid_0's binary_logloss: 0.26829\n",
      "0.03333333333333333\n",
      "[137]\tvalid_0's binary_logloss: 0.26829\n",
      "0.03333333333333333\n",
      "[138]\tvalid_0's binary_logloss: 0.26829\n",
      "0.03333333333333333\n",
      "[139]\tvalid_0's binary_logloss: 0.268296\n",
      "0.03333333333333333\n",
      "[140]\tvalid_0's binary_logloss: 0.268295\n",
      "0.03333333333333333\n",
      "[141]\tvalid_0's binary_logloss: 0.268292\n",
      "0.03333333333333333\n",
      "[142]\tvalid_0's binary_logloss: 0.268288\n",
      "0.03333333333333333\n",
      "[143]\tvalid_0's binary_logloss: 0.268285\n",
      "0.03333333333333333\n",
      "[144]\tvalid_0's binary_logloss: 0.268284\n",
      "0.03333333333333333\n",
      "[145]\tvalid_0's binary_logloss: 0.268283\n",
      "0.03333333333333333\n",
      "[146]\tvalid_0's binary_logloss: 0.268282\n",
      "Early stopping, best iteration is:\n",
      "[126]\tvalid_0's binary_logloss: 0.268267\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree_index</th>\n",
       "      <th>node_depth</th>\n",
       "      <th>node_index</th>\n",
       "      <th>left_child</th>\n",
       "      <th>right_child</th>\n",
       "      <th>parent_index</th>\n",
       "      <th>split_feature</th>\n",
       "      <th>split_gain</th>\n",
       "      <th>threshold</th>\n",
       "      <th>decision_type</th>\n",
       "      <th>missing_direction</th>\n",
       "      <th>missing_type</th>\n",
       "      <th>value</th>\n",
       "      <th>weight</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0-S0</td>\n",
       "      <td>0-S1</td>\n",
       "      <td>0-L1</td>\n",
       "      <td>None</td>\n",
       "      <td>5萬捨てカウント</td>\n",
       "      <td>424496.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;=</td>\n",
       "      <td>left</td>\n",
       "      <td>None</td>\n",
       "      <td>-2.401670</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>34173792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0-S1</td>\n",
       "      <td>0-S2</td>\n",
       "      <td>0-S4</td>\n",
       "      <td>0-S0</td>\n",
       "      <td>8萬捨てカウント</td>\n",
       "      <td>104382.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;=</td>\n",
       "      <td>left</td>\n",
       "      <td>None</td>\n",
       "      <td>-2.386540</td>\n",
       "      <td>2.282100e+06</td>\n",
       "      <td>29968878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0-S2</td>\n",
       "      <td>0-S3</td>\n",
       "      <td>0-S7</td>\n",
       "      <td>0-S1</td>\n",
       "      <td>2萬捨てカウント</td>\n",
       "      <td>80941.898438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;=</td>\n",
       "      <td>left</td>\n",
       "      <td>None</td>\n",
       "      <td>-2.375550</td>\n",
       "      <td>1.805790e+06</td>\n",
       "      <td>23713902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0-S3</td>\n",
       "      <td>0-S5</td>\n",
       "      <td>0-S6</td>\n",
       "      <td>0-S2</td>\n",
       "      <td>捨牌8</td>\n",
       "      <td>61235.601562</td>\n",
       "      <td>0||3||4||6||7</td>\n",
       "      <td>==</td>\n",
       "      <td>right</td>\n",
       "      <td>None</td>\n",
       "      <td>-2.364710</td>\n",
       "      <td>1.430700e+06</td>\n",
       "      <td>18788112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0-S5</td>\n",
       "      <td>0-S16</td>\n",
       "      <td>0-S9</td>\n",
       "      <td>0-S3</td>\n",
       "      <td>捨牌5</td>\n",
       "      <td>15134.099609</td>\n",
       "      <td>0||3||4||6||7</td>\n",
       "      <td>==</td>\n",
       "      <td>right</td>\n",
       "      <td>None</td>\n",
       "      <td>-2.383190</td>\n",
       "      <td>7.960810e+05</td>\n",
       "      <td>10454232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7681</th>\n",
       "      <td>125</td>\n",
       "      <td>9</td>\n",
       "      <td>125-L27</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>125-S26</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.000523</td>\n",
       "      <td>9.968617e+04</td>\n",
       "      <td>1229145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7682</th>\n",
       "      <td>125</td>\n",
       "      <td>8</td>\n",
       "      <td>125-L26</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>125-S25</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>1.520954e+05</td>\n",
       "      <td>1727436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7683</th>\n",
       "      <td>125</td>\n",
       "      <td>7</td>\n",
       "      <td>125-L25</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>125-S24</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.000254</td>\n",
       "      <td>2.120238e+05</td>\n",
       "      <td>2653752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7684</th>\n",
       "      <td>125</td>\n",
       "      <td>4</td>\n",
       "      <td>125-L10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>125-S9</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.001509</td>\n",
       "      <td>4.713061e+04</td>\n",
       "      <td>532662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7685</th>\n",
       "      <td>125</td>\n",
       "      <td>2</td>\n",
       "      <td>125-L1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>125-S0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.025857</td>\n",
       "      <td>1.647639e+02</td>\n",
       "      <td>187200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7686 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tree_index  node_depth node_index left_child right_child parent_index  \\\n",
       "0              0           1       0-S0       0-S1        0-L1         None   \n",
       "1              0           2       0-S1       0-S2        0-S4         0-S0   \n",
       "2              0           3       0-S2       0-S3        0-S7         0-S1   \n",
       "3              0           4       0-S3       0-S5        0-S6         0-S2   \n",
       "4              0           5       0-S5      0-S16        0-S9         0-S3   \n",
       "...          ...         ...        ...        ...         ...          ...   \n",
       "7681         125           9    125-L27       None        None      125-S26   \n",
       "7682         125           8    125-L26       None        None      125-S25   \n",
       "7683         125           7    125-L25       None        None      125-S24   \n",
       "7684         125           4    125-L10       None        None       125-S9   \n",
       "7685         125           2     125-L1       None        None       125-S0   \n",
       "\n",
       "     split_feature     split_gain      threshold decision_type  \\\n",
       "0         5萬捨てカウント  424496.000000            0.0            <=   \n",
       "1         8萬捨てカウント  104382.000000            0.0            <=   \n",
       "2         2萬捨てカウント   80941.898438            0.0            <=   \n",
       "3              捨牌8   61235.601562  0||3||4||6||7            ==   \n",
       "4              捨牌5   15134.099609  0||3||4||6||7            ==   \n",
       "...            ...            ...            ...           ...   \n",
       "7681          None            NaN           None          None   \n",
       "7682          None            NaN           None          None   \n",
       "7683          None            NaN           None          None   \n",
       "7684          None            NaN           None          None   \n",
       "7685          None            NaN           None          None   \n",
       "\n",
       "     missing_direction missing_type     value        weight     count  \n",
       "0                 left         None -2.401670  0.000000e+00  34173792  \n",
       "1                 left         None -2.386540  2.282100e+06  29968878  \n",
       "2                 left         None -2.375550  1.805790e+06  23713902  \n",
       "3                right         None -2.364710  1.430700e+06  18788112  \n",
       "4                right         None -2.383190  7.960810e+05  10454232  \n",
       "...                ...          ...       ...           ...       ...  \n",
       "7681              None         None -0.000523  9.968617e+04   1229145  \n",
       "7682              None         None  0.001333  1.520954e+05   1727436  \n",
       "7683              None         None -0.000254  2.120238e+05   2653752  \n",
       "7684              None         None -0.001509  4.713061e+04    532662  \n",
       "7685              None         None -0.025857  1.647639e+02    187200  \n",
       "\n",
       "[7686 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps = 1\n",
    "def helper(n):\n",
    "    k = n//50\n",
    "    r = 0.1 / (k+1)\n",
    "    print(r)\n",
    "    return r\n",
    "train_and_test('data/both', early_stopping_rounds=20, num_boost_round=1000, learning_rates=helper, verbose_eval=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "37402d29-ee2e-4399-9b02-3caa9544d8aa",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hahho\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\basic.py:1705: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['捨牌1', '捨牌10', '捨牌11', '捨牌12', '捨牌13', '捨牌14', '捨牌15', '捨牌16', '捨牌17', '捨牌18', '捨牌19', '捨牌2', '捨牌20', '捨牌3', '捨牌4', '捨牌5', '捨牌6', '捨牌7', '捨牌8', '捨牌9']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 158454, number of negative: 1740090\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074908 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 626\n",
      "[LightGBM] [Info] Number of data points in the train set: 1898544, number of used features: 19\n",
      "0.1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.083461 -> initscore=-2.396228\n",
      "[LightGBM] [Info] Start training from score -2.396228\n",
      "[1]\tvalid_0's binary_logloss: 0.283918\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hahho\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "c:\\users\\hahho\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\tvalid_0's binary_logloss: 0.282543\n",
      "0.1\n",
      "[3]\tvalid_0's binary_logloss: 0.281405\n",
      "0.1\n",
      "[4]\tvalid_0's binary_logloss: 0.280422\n",
      "0.1\n",
      "[5]\tvalid_0's binary_logloss: 0.279554\n",
      "0.1\n",
      "[6]\tvalid_0's binary_logloss: 0.278791\n",
      "0.1\n",
      "[7]\tvalid_0's binary_logloss: 0.278095\n",
      "0.1\n",
      "[8]\tvalid_0's binary_logloss: 0.277484\n",
      "0.1\n",
      "[9]\tvalid_0's binary_logloss: 0.276919\n",
      "0.1\n",
      "[10]\tvalid_0's binary_logloss: 0.276417\n",
      "0.1\n",
      "[11]\tvalid_0's binary_logloss: 0.275935\n",
      "0.1\n",
      "[12]\tvalid_0's binary_logloss: 0.275499\n",
      "0.1\n",
      "[13]\tvalid_0's binary_logloss: 0.275098\n",
      "0.1\n",
      "[14]\tvalid_0's binary_logloss: 0.274731\n",
      "0.1\n",
      "[15]\tvalid_0's binary_logloss: 0.274426\n",
      "0.1\n",
      "[16]\tvalid_0's binary_logloss: 0.274142\n",
      "0.1\n",
      "[17]\tvalid_0's binary_logloss: 0.273853\n",
      "0.1\n",
      "[18]\tvalid_0's binary_logloss: 0.273577\n",
      "0.1\n",
      "[19]\tvalid_0's binary_logloss: 0.273356\n",
      "0.1\n",
      "[20]\tvalid_0's binary_logloss: 0.273155\n",
      "0.1\n",
      "[21]\tvalid_0's binary_logloss: 0.272957\n",
      "0.1\n",
      "[22]\tvalid_0's binary_logloss: 0.272774\n",
      "0.1\n",
      "[23]\tvalid_0's binary_logloss: 0.272629\n",
      "0.1\n",
      "[24]\tvalid_0's binary_logloss: 0.272461\n",
      "0.1\n",
      "[25]\tvalid_0's binary_logloss: 0.272351\n",
      "0.1\n",
      "[26]\tvalid_0's binary_logloss: 0.272232\n",
      "0.1\n",
      "[27]\tvalid_0's binary_logloss: 0.272097\n",
      "0.1\n",
      "[28]\tvalid_0's binary_logloss: 0.272003\n",
      "0.1\n",
      "[29]\tvalid_0's binary_logloss: 0.271908\n",
      "0.1\n",
      "[30]\tvalid_0's binary_logloss: 0.271806\n",
      "0.1\n",
      "[31]\tvalid_0's binary_logloss: 0.271711\n",
      "0.1\n",
      "[32]\tvalid_0's binary_logloss: 0.271635\n",
      "0.1\n",
      "[33]\tvalid_0's binary_logloss: 0.271527\n",
      "0.1\n",
      "[34]\tvalid_0's binary_logloss: 0.271421\n",
      "0.1\n",
      "[35]\tvalid_0's binary_logloss: 0.271374\n",
      "0.1\n",
      "[36]\tvalid_0's binary_logloss: 0.271332\n",
      "0.1\n",
      "[37]\tvalid_0's binary_logloss: 0.271264\n",
      "0.1\n",
      "[38]\tvalid_0's binary_logloss: 0.271233\n",
      "0.1\n",
      "[39]\tvalid_0's binary_logloss: 0.271192\n",
      "0.1\n",
      "[40]\tvalid_0's binary_logloss: 0.271118\n",
      "0.1\n",
      "[41]\tvalid_0's binary_logloss: 0.271082\n",
      "0.1\n",
      "[42]\tvalid_0's binary_logloss: 0.271055\n",
      "0.1\n",
      "[43]\tvalid_0's binary_logloss: 0.271019\n",
      "0.1\n",
      "[44]\tvalid_0's binary_logloss: 0.270978\n",
      "0.1\n",
      "[45]\tvalid_0's binary_logloss: 0.270949\n",
      "0.1\n",
      "[46]\tvalid_0's binary_logloss: 0.270901\n",
      "0.1\n",
      "[47]\tvalid_0's binary_logloss: 0.270881\n",
      "0.1\n",
      "[48]\tvalid_0's binary_logloss: 0.270857\n",
      "0.1\n",
      "[49]\tvalid_0's binary_logloss: 0.270836\n",
      "0.1\n",
      "[50]\tvalid_0's binary_logloss: 0.270778\n",
      "0.05\n",
      "[51]\tvalid_0's binary_logloss: 0.270769\n",
      "0.05\n",
      "[52]\tvalid_0's binary_logloss: 0.270759\n",
      "0.05\n",
      "[53]\tvalid_0's binary_logloss: 0.270731\n",
      "0.05\n",
      "[54]\tvalid_0's binary_logloss: 0.270719\n",
      "0.05\n",
      "[55]\tvalid_0's binary_logloss: 0.270713\n",
      "0.05\n",
      "[56]\tvalid_0's binary_logloss: 0.270706\n",
      "0.05\n",
      "[57]\tvalid_0's binary_logloss: 0.270694\n",
      "0.05\n",
      "[58]\tvalid_0's binary_logloss: 0.270679\n",
      "0.05\n",
      "[59]\tvalid_0's binary_logloss: 0.270676\n",
      "0.05\n",
      "[60]\tvalid_0's binary_logloss: 0.270669\n",
      "0.05\n",
      "[61]\tvalid_0's binary_logloss: 0.270661\n",
      "0.05\n",
      "[62]\tvalid_0's binary_logloss: 0.270655\n",
      "0.05\n",
      "[63]\tvalid_0's binary_logloss: 0.270651\n",
      "0.05\n",
      "[64]\tvalid_0's binary_logloss: 0.270642\n",
      "0.05\n",
      "[65]\tvalid_0's binary_logloss: 0.27064\n",
      "0.05\n",
      "[66]\tvalid_0's binary_logloss: 0.270636\n",
      "0.05\n",
      "[67]\tvalid_0's binary_logloss: 0.270605\n",
      "0.05\n",
      "[68]\tvalid_0's binary_logloss: 0.270602\n",
      "0.05\n",
      "[69]\tvalid_0's binary_logloss: 0.2706\n",
      "0.05\n",
      "[70]\tvalid_0's binary_logloss: 0.27059\n",
      "0.05\n",
      "[71]\tvalid_0's binary_logloss: 0.270587\n",
      "0.05\n",
      "[72]\tvalid_0's binary_logloss: 0.270582\n",
      "0.05\n",
      "[73]\tvalid_0's binary_logloss: 0.270574\n",
      "0.05\n",
      "[74]\tvalid_0's binary_logloss: 0.270574\n",
      "0.05\n",
      "[75]\tvalid_0's binary_logloss: 0.27057\n",
      "0.05\n",
      "[76]\tvalid_0's binary_logloss: 0.270568\n",
      "0.05\n",
      "[77]\tvalid_0's binary_logloss: 0.270558\n",
      "0.05\n",
      "[78]\tvalid_0's binary_logloss: 0.270559\n",
      "0.05\n",
      "[79]\tvalid_0's binary_logloss: 0.270555\n",
      "0.05\n",
      "[80]\tvalid_0's binary_logloss: 0.270554\n",
      "0.05\n",
      "[81]\tvalid_0's binary_logloss: 0.270552\n",
      "0.05\n",
      "[82]\tvalid_0's binary_logloss: 0.270548\n",
      "0.05\n",
      "[83]\tvalid_0's binary_logloss: 0.270544\n",
      "0.05\n",
      "[84]\tvalid_0's binary_logloss: 0.27054\n",
      "0.05\n",
      "[85]\tvalid_0's binary_logloss: 0.270542\n",
      "0.05\n",
      "[86]\tvalid_0's binary_logloss: 0.270517\n",
      "0.05\n",
      "[87]\tvalid_0's binary_logloss: 0.270493\n",
      "0.05\n",
      "[88]\tvalid_0's binary_logloss: 0.270492\n",
      "0.05\n",
      "[89]\tvalid_0's binary_logloss: 0.270486\n",
      "0.05\n",
      "[90]\tvalid_0's binary_logloss: 0.270483\n",
      "0.05\n",
      "[91]\tvalid_0's binary_logloss: 0.270477\n",
      "0.05\n",
      "[92]\tvalid_0's binary_logloss: 0.270479\n",
      "0.05\n",
      "[93]\tvalid_0's binary_logloss: 0.270476\n",
      "0.05\n",
      "[94]\tvalid_0's binary_logloss: 0.270475\n",
      "0.05\n",
      "[95]\tvalid_0's binary_logloss: 0.270474\n",
      "0.05\n",
      "[96]\tvalid_0's binary_logloss: 0.270473\n",
      "0.05\n",
      "[97]\tvalid_0's binary_logloss: 0.270471\n",
      "0.05\n",
      "[98]\tvalid_0's binary_logloss: 0.270473\n",
      "0.05\n",
      "[99]\tvalid_0's binary_logloss: 0.270473\n",
      "0.05\n",
      "[100]\tvalid_0's binary_logloss: 0.270468\n",
      "0.03333333333333333\n",
      "[101]\tvalid_0's binary_logloss: 0.270462\n",
      "0.03333333333333333\n",
      "[102]\tvalid_0's binary_logloss: 0.270462\n",
      "0.03333333333333333\n",
      "[103]\tvalid_0's binary_logloss: 0.270463\n",
      "0.03333333333333333\n",
      "[104]\tvalid_0's binary_logloss: 0.270463\n",
      "0.03333333333333333\n",
      "[105]\tvalid_0's binary_logloss: 0.270464\n",
      "0.03333333333333333\n",
      "[106]\tvalid_0's binary_logloss: 0.270461\n",
      "0.03333333333333333\n",
      "[107]\tvalid_0's binary_logloss: 0.270458\n",
      "0.03333333333333333\n",
      "[108]\tvalid_0's binary_logloss: 0.270453\n",
      "0.03333333333333333\n",
      "[109]\tvalid_0's binary_logloss: 0.270451\n",
      "0.03333333333333333\n",
      "[110]\tvalid_0's binary_logloss: 0.270453\n",
      "0.03333333333333333\n",
      "[111]\tvalid_0's binary_logloss: 0.270452\n",
      "0.03333333333333333\n",
      "[112]\tvalid_0's binary_logloss: 0.270449\n",
      "0.03333333333333333\n",
      "[113]\tvalid_0's binary_logloss: 0.270449\n",
      "0.03333333333333333\n",
      "[114]\tvalid_0's binary_logloss: 0.270446\n",
      "0.03333333333333333\n",
      "[115]\tvalid_0's binary_logloss: 0.270445\n",
      "0.03333333333333333\n",
      "[116]\tvalid_0's binary_logloss: 0.270434\n",
      "0.03333333333333333\n",
      "[117]\tvalid_0's binary_logloss: 0.270433\n",
      "0.03333333333333333\n",
      "[118]\tvalid_0's binary_logloss: 0.270433\n",
      "0.03333333333333333\n",
      "[119]\tvalid_0's binary_logloss: 0.270429\n",
      "0.03333333333333333\n",
      "[120]\tvalid_0's binary_logloss: 0.270429\n",
      "0.03333333333333333\n",
      "[121]\tvalid_0's binary_logloss: 0.270427\n",
      "0.03333333333333333\n",
      "[122]\tvalid_0's binary_logloss: 0.270425\n",
      "0.03333333333333333\n",
      "[123]\tvalid_0's binary_logloss: 0.270424\n",
      "0.03333333333333333\n",
      "[124]\tvalid_0's binary_logloss: 0.270422\n",
      "0.03333333333333333\n",
      "[125]\tvalid_0's binary_logloss: 0.27042\n",
      "0.03333333333333333\n",
      "[126]\tvalid_0's binary_logloss: 0.270416\n",
      "0.03333333333333333\n",
      "[127]\tvalid_0's binary_logloss: 0.270415\n",
      "0.03333333333333333\n",
      "[128]\tvalid_0's binary_logloss: 0.270416\n",
      "0.03333333333333333\n",
      "[129]\tvalid_0's binary_logloss: 0.270416\n",
      "0.03333333333333333\n",
      "[130]\tvalid_0's binary_logloss: 0.270414\n",
      "0.03333333333333333\n",
      "[131]\tvalid_0's binary_logloss: 0.27041\n",
      "0.03333333333333333\n",
      "[132]\tvalid_0's binary_logloss: 0.270409\n",
      "0.03333333333333333\n",
      "[133]\tvalid_0's binary_logloss: 0.270408\n",
      "0.03333333333333333\n",
      "[134]\tvalid_0's binary_logloss: 0.270406\n",
      "0.03333333333333333\n",
      "[135]\tvalid_0's binary_logloss: 0.270407\n",
      "0.03333333333333333\n",
      "[136]\tvalid_0's binary_logloss: 0.270406\n",
      "0.03333333333333333\n",
      "[137]\tvalid_0's binary_logloss: 0.270404\n",
      "0.03333333333333333\n",
      "[138]\tvalid_0's binary_logloss: 0.270403\n",
      "0.03333333333333333\n",
      "[139]\tvalid_0's binary_logloss: 0.270401\n",
      "0.03333333333333333\n",
      "[140]\tvalid_0's binary_logloss: 0.270399\n",
      "0.03333333333333333\n",
      "[141]\tvalid_0's binary_logloss: 0.270398\n",
      "0.03333333333333333\n",
      "[142]\tvalid_0's binary_logloss: 0.270396\n",
      "0.03333333333333333\n",
      "[143]\tvalid_0's binary_logloss: 0.270394\n",
      "0.03333333333333333\n",
      "[144]\tvalid_0's binary_logloss: 0.270393\n",
      "0.03333333333333333\n",
      "[145]\tvalid_0's binary_logloss: 0.270394\n",
      "0.03333333333333333\n",
      "[146]\tvalid_0's binary_logloss: 0.270387\n",
      "0.03333333333333333\n",
      "[147]\tvalid_0's binary_logloss: 0.270386\n",
      "0.03333333333333333\n",
      "[148]\tvalid_0's binary_logloss: 0.270386\n",
      "0.03333333333333333\n",
      "[149]\tvalid_0's binary_logloss: 0.270388\n",
      "0.03333333333333333\n",
      "[150]\tvalid_0's binary_logloss: 0.270389\n",
      "0.025\n",
      "[151]\tvalid_0's binary_logloss: 0.270387\n",
      "0.025\n",
      "[152]\tvalid_0's binary_logloss: 0.270385\n",
      "0.025\n",
      "[153]\tvalid_0's binary_logloss: 0.270384\n",
      "0.025\n",
      "[154]\tvalid_0's binary_logloss: 0.270385\n",
      "0.025\n",
      "[155]\tvalid_0's binary_logloss: 0.270383\n",
      "0.025\n",
      "[156]\tvalid_0's binary_logloss: 0.270381\n",
      "0.025\n",
      "[157]\tvalid_0's binary_logloss: 0.27038\n",
      "0.025\n",
      "[158]\tvalid_0's binary_logloss: 0.27038\n",
      "0.025\n",
      "[159]\tvalid_0's binary_logloss: 0.27038\n",
      "0.025\n",
      "[160]\tvalid_0's binary_logloss: 0.270378\n",
      "0.025\n",
      "[161]\tvalid_0's binary_logloss: 0.270378\n",
      "0.025\n",
      "[162]\tvalid_0's binary_logloss: 0.270378\n",
      "0.025\n",
      "[163]\tvalid_0's binary_logloss: 0.270377\n",
      "0.025\n",
      "[164]\tvalid_0's binary_logloss: 0.270376\n",
      "0.025\n",
      "[165]\tvalid_0's binary_logloss: 0.270374\n",
      "0.025\n",
      "[166]\tvalid_0's binary_logloss: 0.270374\n",
      "0.025\n",
      "[167]\tvalid_0's binary_logloss: 0.270374\n",
      "0.025\n",
      "[168]\tvalid_0's binary_logloss: 0.270371\n",
      "0.025\n",
      "[169]\tvalid_0's binary_logloss: 0.270362\n",
      "0.025\n",
      "[170]\tvalid_0's binary_logloss: 0.270361\n",
      "0.025\n",
      "[171]\tvalid_0's binary_logloss: 0.27036\n",
      "0.025\n",
      "[172]\tvalid_0's binary_logloss: 0.27036\n",
      "0.025\n",
      "[173]\tvalid_0's binary_logloss: 0.270358\n",
      "0.025\n",
      "[174]\tvalid_0's binary_logloss: 0.270358\n",
      "0.025\n",
      "[175]\tvalid_0's binary_logloss: 0.270357\n",
      "0.025\n",
      "[176]\tvalid_0's binary_logloss: 0.270355\n",
      "0.025\n",
      "[177]\tvalid_0's binary_logloss: 0.270356\n",
      "0.025\n",
      "[178]\tvalid_0's binary_logloss: 0.270354\n",
      "0.025\n",
      "[179]\tvalid_0's binary_logloss: 0.270354\n",
      "0.025\n",
      "[180]\tvalid_0's binary_logloss: 0.270352\n",
      "0.025\n",
      "[181]\tvalid_0's binary_logloss: 0.270352\n",
      "0.025\n",
      "[182]\tvalid_0's binary_logloss: 0.270351\n",
      "0.025\n",
      "[183]\tvalid_0's binary_logloss: 0.270349\n",
      "0.025\n",
      "[184]\tvalid_0's binary_logloss: 0.270349\n",
      "0.025\n",
      "[185]\tvalid_0's binary_logloss: 0.270348\n",
      "0.025\n",
      "[186]\tvalid_0's binary_logloss: 0.270347\n",
      "0.025\n",
      "[187]\tvalid_0's binary_logloss: 0.270346\n",
      "0.025\n",
      "[188]\tvalid_0's binary_logloss: 0.270345\n",
      "0.025\n",
      "[189]\tvalid_0's binary_logloss: 0.270334\n",
      "0.025\n",
      "[190]\tvalid_0's binary_logloss: 0.270334\n",
      "0.025\n",
      "[191]\tvalid_0's binary_logloss: 0.270332\n",
      "0.025\n",
      "[192]\tvalid_0's binary_logloss: 0.270332\n",
      "0.025\n",
      "[193]\tvalid_0's binary_logloss: 0.270331\n",
      "0.025\n",
      "[194]\tvalid_0's binary_logloss: 0.270331\n",
      "0.025\n",
      "[195]\tvalid_0's binary_logloss: 0.27033\n",
      "0.025\n",
      "[196]\tvalid_0's binary_logloss: 0.270331\n",
      "0.025\n",
      "[197]\tvalid_0's binary_logloss: 0.27033\n",
      "0.025\n",
      "[198]\tvalid_0's binary_logloss: 0.27033\n",
      "0.025\n",
      "[199]\tvalid_0's binary_logloss: 0.27033\n",
      "0.025\n",
      "[200]\tvalid_0's binary_logloss: 0.270329\n",
      "0.02\n",
      "[201]\tvalid_0's binary_logloss: 0.270328\n",
      "0.02\n",
      "[202]\tvalid_0's binary_logloss: 0.270327\n",
      "0.02\n",
      "[203]\tvalid_0's binary_logloss: 0.270328\n",
      "0.02\n",
      "[204]\tvalid_0's binary_logloss: 0.270328\n",
      "0.02\n",
      "[205]\tvalid_0's binary_logloss: 0.270328\n",
      "0.02\n",
      "[206]\tvalid_0's binary_logloss: 0.270327\n",
      "0.02\n",
      "[207]\tvalid_0's binary_logloss: 0.270327\n",
      "0.02\n",
      "[208]\tvalid_0's binary_logloss: 0.270328\n",
      "0.02\n",
      "[209]\tvalid_0's binary_logloss: 0.270326\n",
      "0.02\n",
      "[210]\tvalid_0's binary_logloss: 0.270326\n",
      "0.02\n",
      "[211]\tvalid_0's binary_logloss: 0.270327\n",
      "0.02\n",
      "[212]\tvalid_0's binary_logloss: 0.270327\n",
      "0.02\n",
      "[213]\tvalid_0's binary_logloss: 0.270326\n",
      "0.02\n",
      "[214]\tvalid_0's binary_logloss: 0.27032\n",
      "0.02\n",
      "[215]\tvalid_0's binary_logloss: 0.270321\n",
      "0.02\n",
      "[216]\tvalid_0's binary_logloss: 0.270321\n",
      "0.02\n",
      "[217]\tvalid_0's binary_logloss: 0.27032\n",
      "0.02\n",
      "[218]\tvalid_0's binary_logloss: 0.27032\n",
      "0.02\n",
      "[219]\tvalid_0's binary_logloss: 0.270319\n",
      "0.02\n",
      "[220]\tvalid_0's binary_logloss: 0.270319\n",
      "0.02\n",
      "[221]\tvalid_0's binary_logloss: 0.270318\n",
      "0.02\n",
      "[222]\tvalid_0's binary_logloss: 0.270318\n",
      "0.02\n",
      "[223]\tvalid_0's binary_logloss: 0.270317\n",
      "0.02\n",
      "[224]\tvalid_0's binary_logloss: 0.270316\n",
      "0.02\n",
      "[225]\tvalid_0's binary_logloss: 0.270317\n",
      "0.02\n",
      "[226]\tvalid_0's binary_logloss: 0.270311\n",
      "0.02\n",
      "[227]\tvalid_0's binary_logloss: 0.270312\n",
      "0.02\n",
      "[228]\tvalid_0's binary_logloss: 0.270311\n",
      "0.02\n",
      "[229]\tvalid_0's binary_logloss: 0.27031\n",
      "0.02\n",
      "[230]\tvalid_0's binary_logloss: 0.270309\n",
      "0.02\n",
      "[231]\tvalid_0's binary_logloss: 0.270308\n",
      "0.02\n",
      "[232]\tvalid_0's binary_logloss: 0.270308\n",
      "0.02\n",
      "[233]\tvalid_0's binary_logloss: 0.270308\n",
      "0.02\n",
      "[234]\tvalid_0's binary_logloss: 0.270308\n",
      "0.02\n",
      "[235]\tvalid_0's binary_logloss: 0.270307\n",
      "0.02\n",
      "[236]\tvalid_0's binary_logloss: 0.270306\n",
      "0.02\n",
      "[237]\tvalid_0's binary_logloss: 0.270306\n",
      "0.02\n",
      "[238]\tvalid_0's binary_logloss: 0.270305\n",
      "0.02\n",
      "[239]\tvalid_0's binary_logloss: 0.270306\n",
      "0.02\n",
      "[240]\tvalid_0's binary_logloss: 0.270305\n",
      "0.02\n",
      "[241]\tvalid_0's binary_logloss: 0.270305\n",
      "0.02\n",
      "[242]\tvalid_0's binary_logloss: 0.270304\n",
      "0.02\n",
      "[243]\tvalid_0's binary_logloss: 0.270303\n",
      "0.02\n",
      "[244]\tvalid_0's binary_logloss: 0.270303\n",
      "0.02\n",
      "[245]\tvalid_0's binary_logloss: 0.270302\n",
      "0.02\n",
      "[246]\tvalid_0's binary_logloss: 0.270302\n",
      "0.02\n",
      "[247]\tvalid_0's binary_logloss: 0.270301\n",
      "0.02\n",
      "[248]\tvalid_0's binary_logloss: 0.270301\n",
      "0.02\n",
      "[249]\tvalid_0's binary_logloss: 0.270301\n",
      "0.02\n",
      "[250]\tvalid_0's binary_logloss: 0.270301\n",
      "0.016666666666666666\n",
      "[251]\tvalid_0's binary_logloss: 0.2703\n",
      "0.016666666666666666\n",
      "[252]\tvalid_0's binary_logloss: 0.270301\n",
      "0.016666666666666666\n",
      "[253]\tvalid_0's binary_logloss: 0.270301\n",
      "0.016666666666666666\n",
      "[254]\tvalid_0's binary_logloss: 0.270301\n",
      "0.016666666666666666\n",
      "[255]\tvalid_0's binary_logloss: 0.270301\n",
      "0.016666666666666666\n",
      "[256]\tvalid_0's binary_logloss: 0.270301\n",
      "0.016666666666666666\n",
      "[257]\tvalid_0's binary_logloss: 0.270301\n",
      "0.016666666666666666\n",
      "[258]\tvalid_0's binary_logloss: 0.270301\n",
      "0.016666666666666666\n",
      "[259]\tvalid_0's binary_logloss: 0.270301\n",
      "0.016666666666666666\n",
      "[260]\tvalid_0's binary_logloss: 0.270301\n",
      "0.016666666666666666\n",
      "[261]\tvalid_0's binary_logloss: 0.270301\n",
      "0.016666666666666666\n",
      "[262]\tvalid_0's binary_logloss: 0.2703\n",
      "0.016666666666666666\n",
      "[263]\tvalid_0's binary_logloss: 0.2703\n",
      "0.016666666666666666\n",
      "[264]\tvalid_0's binary_logloss: 0.270299\n",
      "0.016666666666666666\n",
      "[265]\tvalid_0's binary_logloss: 0.270299\n",
      "0.016666666666666666\n",
      "[266]\tvalid_0's binary_logloss: 0.2703\n",
      "0.016666666666666666\n",
      "[267]\tvalid_0's binary_logloss: 0.270298\n",
      "0.016666666666666666\n",
      "[268]\tvalid_0's binary_logloss: 0.270293\n",
      "0.016666666666666666\n",
      "[269]\tvalid_0's binary_logloss: 0.270293\n",
      "0.016666666666666666\n",
      "[270]\tvalid_0's binary_logloss: 0.270293\n",
      "0.016666666666666666\n",
      "[271]\tvalid_0's binary_logloss: 0.270293\n",
      "0.016666666666666666\n",
      "[272]\tvalid_0's binary_logloss: 0.270292\n",
      "0.016666666666666666\n",
      "[273]\tvalid_0's binary_logloss: 0.270292\n",
      "0.016666666666666666\n",
      "[274]\tvalid_0's binary_logloss: 0.270291\n",
      "0.016666666666666666\n",
      "[275]\tvalid_0's binary_logloss: 0.270291\n",
      "0.016666666666666666\n",
      "[276]\tvalid_0's binary_logloss: 0.270287\n",
      "0.016666666666666666\n",
      "[277]\tvalid_0's binary_logloss: 0.270286\n",
      "0.016666666666666666\n",
      "[278]\tvalid_0's binary_logloss: 0.270287\n",
      "0.016666666666666666\n",
      "[279]\tvalid_0's binary_logloss: 0.270287\n",
      "0.016666666666666666\n",
      "[280]\tvalid_0's binary_logloss: 0.270287\n",
      "0.016666666666666666\n",
      "[281]\tvalid_0's binary_logloss: 0.270288\n",
      "0.016666666666666666\n",
      "[282]\tvalid_0's binary_logloss: 0.270288\n",
      "0.016666666666666666\n",
      "[283]\tvalid_0's binary_logloss: 0.270287\n",
      "0.016666666666666666\n",
      "[284]\tvalid_0's binary_logloss: 0.270287\n",
      "0.016666666666666666\n",
      "[285]\tvalid_0's binary_logloss: 0.270288\n",
      "0.016666666666666666\n",
      "[286]\tvalid_0's binary_logloss: 0.270289\n",
      "0.016666666666666666\n",
      "[287]\tvalid_0's binary_logloss: 0.270289\n",
      "0.016666666666666666\n",
      "[288]\tvalid_0's binary_logloss: 0.270289\n",
      "0.016666666666666666\n",
      "[289]\tvalid_0's binary_logloss: 0.270289\n",
      "0.016666666666666666\n",
      "[290]\tvalid_0's binary_logloss: 0.27029\n",
      "0.016666666666666666\n",
      "[291]\tvalid_0's binary_logloss: 0.27029\n",
      "0.016666666666666666\n",
      "[292]\tvalid_0's binary_logloss: 0.27029\n",
      "0.016666666666666666\n",
      "[293]\tvalid_0's binary_logloss: 0.27029\n",
      "0.016666666666666666\n",
      "[294]\tvalid_0's binary_logloss: 0.270289\n",
      "0.016666666666666666\n",
      "[295]\tvalid_0's binary_logloss: 0.270289\n",
      "0.016666666666666666\n",
      "[296]\tvalid_0's binary_logloss: 0.270289\n",
      "0.016666666666666666\n",
      "[297]\tvalid_0's binary_logloss: 0.270288\n",
      "Early stopping, best iteration is:\n",
      "[277]\tvalid_0's binary_logloss: 0.270286\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree_index</th>\n",
       "      <th>node_depth</th>\n",
       "      <th>node_index</th>\n",
       "      <th>left_child</th>\n",
       "      <th>right_child</th>\n",
       "      <th>parent_index</th>\n",
       "      <th>split_feature</th>\n",
       "      <th>split_gain</th>\n",
       "      <th>threshold</th>\n",
       "      <th>decision_type</th>\n",
       "      <th>missing_direction</th>\n",
       "      <th>missing_type</th>\n",
       "      <th>value</th>\n",
       "      <th>weight</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0-S0</td>\n",
       "      <td>0-S6</td>\n",
       "      <td>0-S1</td>\n",
       "      <td>None</td>\n",
       "      <td>捨牌5</td>\n",
       "      <td>3620.010010</td>\n",
       "      <td>0||2||3||5||7||8</td>\n",
       "      <td>==</td>\n",
       "      <td>right</td>\n",
       "      <td>None</td>\n",
       "      <td>-2.396230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1898544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0-S6</td>\n",
       "      <td>0-L0</td>\n",
       "      <td>0-S18</td>\n",
       "      <td>0-S0</td>\n",
       "      <td>捨牌5</td>\n",
       "      <td>1445.369995</td>\n",
       "      <td>5</td>\n",
       "      <td>==</td>\n",
       "      <td>right</td>\n",
       "      <td>None</td>\n",
       "      <td>-2.426860</td>\n",
       "      <td>30472.700000</td>\n",
       "      <td>398361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0-L0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0-S6</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-2.503453</td>\n",
       "      <td>2271.751364</td>\n",
       "      <td>29698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0-S18</td>\n",
       "      <td>0-L7</td>\n",
       "      <td>0-S20</td>\n",
       "      <td>0-S6</td>\n",
       "      <td>捨牌4</td>\n",
       "      <td>445.558014</td>\n",
       "      <td>2||5||8</td>\n",
       "      <td>==</td>\n",
       "      <td>right</td>\n",
       "      <td>None</td>\n",
       "      <td>-2.420650</td>\n",
       "      <td>28200.900000</td>\n",
       "      <td>368663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0-L7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0-S18</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-2.467029</td>\n",
       "      <td>1924.234142</td>\n",
       "      <td>25155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16892</th>\n",
       "      <td>276</td>\n",
       "      <td>6</td>\n",
       "      <td>276-S21</td>\n",
       "      <td>276-L21</td>\n",
       "      <td>276-L22</td>\n",
       "      <td>276-S20</td>\n",
       "      <td>捨牌9</td>\n",
       "      <td>34.544998</td>\n",
       "      <td>0||3||4||9||14||16||17||19||20||21||22||26||27...</td>\n",
       "      <td>==</td>\n",
       "      <td>right</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>7063.460000</td>\n",
       "      <td>90433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16893</th>\n",
       "      <td>276</td>\n",
       "      <td>7</td>\n",
       "      <td>276-L21</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>276-S21</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.000421</td>\n",
       "      <td>6318.266824</td>\n",
       "      <td>81194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16894</th>\n",
       "      <td>276</td>\n",
       "      <td>7</td>\n",
       "      <td>276-L22</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>276-S21</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.003351</td>\n",
       "      <td>745.197600</td>\n",
       "      <td>9239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16895</th>\n",
       "      <td>276</td>\n",
       "      <td>4</td>\n",
       "      <td>276-L4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>276-S3</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.001340</td>\n",
       "      <td>3848.546771</td>\n",
       "      <td>48899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16896</th>\n",
       "      <td>276</td>\n",
       "      <td>2</td>\n",
       "      <td>276-L1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>276-S0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>109332.378262</td>\n",
       "      <td>1491961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16897 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tree_index  node_depth node_index left_child right_child parent_index  \\\n",
       "0               0           1       0-S0       0-S6        0-S1         None   \n",
       "1               0           2       0-S6       0-L0       0-S18         0-S0   \n",
       "2               0           3       0-L0       None        None         0-S6   \n",
       "3               0           3      0-S18       0-L7       0-S20         0-S6   \n",
       "4               0           4       0-L7       None        None        0-S18   \n",
       "...           ...         ...        ...        ...         ...          ...   \n",
       "16892         276           6    276-S21    276-L21     276-L22      276-S20   \n",
       "16893         276           7    276-L21       None        None      276-S21   \n",
       "16894         276           7    276-L22       None        None      276-S21   \n",
       "16895         276           4     276-L4       None        None       276-S3   \n",
       "16896         276           2     276-L1       None        None       276-S0   \n",
       "\n",
       "      split_feature   split_gain  \\\n",
       "0               捨牌5  3620.010010   \n",
       "1               捨牌5  1445.369995   \n",
       "2              None          NaN   \n",
       "3               捨牌4   445.558014   \n",
       "4              None          NaN   \n",
       "...             ...          ...   \n",
       "16892           捨牌9    34.544998   \n",
       "16893          None          NaN   \n",
       "16894          None          NaN   \n",
       "16895          None          NaN   \n",
       "16896          None          NaN   \n",
       "\n",
       "                                               threshold decision_type  \\\n",
       "0                                       0||2||3||5||7||8            ==   \n",
       "1                                                      5            ==   \n",
       "2                                                   None          None   \n",
       "3                                                2||5||8            ==   \n",
       "4                                                   None          None   \n",
       "...                                                  ...           ...   \n",
       "16892  0||3||4||9||14||16||17||19||20||21||22||26||27...            ==   \n",
       "16893                                               None          None   \n",
       "16894                                               None          None   \n",
       "16895                                               None          None   \n",
       "16896                                               None          None   \n",
       "\n",
       "      missing_direction missing_type     value         weight    count  \n",
       "0                 right         None -2.396230       0.000000  1898544  \n",
       "1                 right         None -2.426860   30472.700000   398361  \n",
       "2                  None         None -2.503453    2271.751364    29698  \n",
       "3                 right         None -2.420650   28200.900000   368663  \n",
       "4                  None         None -2.467029    1924.234142    25155  \n",
       "...                 ...          ...       ...            ...      ...  \n",
       "16892             right         None -0.000018    7063.460000    90433  \n",
       "16893              None         None -0.000421    6318.266824    81194  \n",
       "16894              None         None  0.003351     745.197600     9239  \n",
       "16895              None         None -0.001340    3848.546771    48899  \n",
       "16896              None         None -0.000066  109332.378262  1491961  \n",
       "\n",
       "[16897 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps = 1\n",
    "def helper(n):\n",
    "    k = n//50\n",
    "    r = 0.1 / (k+1)\n",
    "    print(r)\n",
    "    return r\n",
    "train_and_test('data/vanilla', early_stopping_rounds=20, num_boost_round=1000, learning_rates=helper, verbose_eval=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8bf81150-4f51-40c6-b9ac-8b7f7c5052ff",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hahho\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\basic.py:1705: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['リーチ前0', 'リーチ前1', 'リーチ前10', 'リーチ前11', 'リーチ前12', 'リーチ前13', 'リーチ前14', 'リーチ前15', 'リーチ前16', 'リーチ前17', 'リーチ前18', 'リーチ前19', 'リーチ前2', 'リーチ前3', 'リーチ前4', 'リーチ前5', 'リーチ前6', 'リーチ前7', 'リーチ前8', 'リーチ前9', '捨牌1', '捨牌10', '捨牌11', '捨牌12', '捨牌13', '捨牌14', '捨牌15', '捨牌16', '捨牌17', '捨牌18', '捨牌19', '捨牌2', '捨牌20', '捨牌3', '捨牌4', '捨牌5', '捨牌6', '捨牌7', '捨牌8', '捨牌9']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 158454, number of negative: 1740090\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.211005 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1394\n",
      "[LightGBM] [Info] Number of data points in the train set: 1898544, number of used features: 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hahho\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "c:\\users\\hahho\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.083461 -> initscore=-2.396228\n",
      "[LightGBM] [Info] Start training from score -2.396228\n",
      "[1]\tvalid_0's binary_logloss: 0.283311\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "0.1\n",
      "[2]\tvalid_0's binary_logloss: 0.281484\n",
      "0.1\n",
      "[3]\tvalid_0's binary_logloss: 0.279944\n",
      "0.1\n",
      "[4]\tvalid_0's binary_logloss: 0.278617\n",
      "0.1\n",
      "[5]\tvalid_0's binary_logloss: 0.277474\n",
      "0.1\n",
      "[6]\tvalid_0's binary_logloss: 0.276483\n",
      "0.1\n",
      "[7]\tvalid_0's binary_logloss: 0.275626\n",
      "0.1\n",
      "[8]\tvalid_0's binary_logloss: 0.274875\n",
      "0.1\n",
      "[9]\tvalid_0's binary_logloss: 0.274202\n",
      "0.1\n",
      "[10]\tvalid_0's binary_logloss: 0.273619\n",
      "0.1\n",
      "[11]\tvalid_0's binary_logloss: 0.273108\n",
      "0.1\n",
      "[12]\tvalid_0's binary_logloss: 0.272665\n",
      "0.1\n",
      "[13]\tvalid_0's binary_logloss: 0.272251\n",
      "0.1\n",
      "[14]\tvalid_0's binary_logloss: 0.271893\n",
      "0.1\n",
      "[15]\tvalid_0's binary_logloss: 0.271573\n",
      "0.1\n",
      "[16]\tvalid_0's binary_logloss: 0.271298\n",
      "0.1\n",
      "[17]\tvalid_0's binary_logloss: 0.271042\n",
      "0.1\n",
      "[18]\tvalid_0's binary_logloss: 0.270808\n",
      "0.1\n",
      "[19]\tvalid_0's binary_logloss: 0.2706\n",
      "0.1\n",
      "[20]\tvalid_0's binary_logloss: 0.27041\n",
      "0.1\n",
      "[21]\tvalid_0's binary_logloss: 0.270245\n",
      "0.1\n",
      "[22]\tvalid_0's binary_logloss: 0.270089\n",
      "0.1\n",
      "[23]\tvalid_0's binary_logloss: 0.269957\n",
      "0.1\n",
      "[24]\tvalid_0's binary_logloss: 0.269821\n",
      "0.1\n",
      "[25]\tvalid_0's binary_logloss: 0.269691\n",
      "0.1\n",
      "[26]\tvalid_0's binary_logloss: 0.269611\n",
      "0.1\n",
      "[27]\tvalid_0's binary_logloss: 0.269502\n",
      "0.1\n",
      "[28]\tvalid_0's binary_logloss: 0.269434\n",
      "0.1\n",
      "[29]\tvalid_0's binary_logloss: 0.269341\n",
      "0.1\n",
      "[30]\tvalid_0's binary_logloss: 0.269264\n",
      "0.1\n",
      "[31]\tvalid_0's binary_logloss: 0.269213\n",
      "0.1\n",
      "[32]\tvalid_0's binary_logloss: 0.269158\n",
      "0.1\n",
      "[33]\tvalid_0's binary_logloss: 0.269115\n",
      "0.1\n",
      "[34]\tvalid_0's binary_logloss: 0.269076\n",
      "0.1\n",
      "[35]\tvalid_0's binary_logloss: 0.269047\n",
      "0.1\n",
      "[36]\tvalid_0's binary_logloss: 0.268991\n",
      "0.1\n",
      "[37]\tvalid_0's binary_logloss: 0.268973\n",
      "0.1\n",
      "[38]\tvalid_0's binary_logloss: 0.268934\n",
      "0.1\n",
      "[39]\tvalid_0's binary_logloss: 0.268917\n",
      "0.1\n",
      "[40]\tvalid_0's binary_logloss: 0.268897\n",
      "0.1\n",
      "[41]\tvalid_0's binary_logloss: 0.268873\n",
      "0.1\n",
      "[42]\tvalid_0's binary_logloss: 0.268855\n",
      "0.1\n",
      "[43]\tvalid_0's binary_logloss: 0.268828\n",
      "0.1\n",
      "[44]\tvalid_0's binary_logloss: 0.268817\n",
      "0.1\n",
      "[45]\tvalid_0's binary_logloss: 0.2688\n",
      "0.1\n",
      "[46]\tvalid_0's binary_logloss: 0.268774\n",
      "0.1\n",
      "[47]\tvalid_0's binary_logloss: 0.26877\n",
      "0.1\n",
      "[48]\tvalid_0's binary_logloss: 0.268759\n",
      "0.1\n",
      "[49]\tvalid_0's binary_logloss: 0.268755\n",
      "0.1\n",
      "[50]\tvalid_0's binary_logloss: 0.268749\n",
      "0.05\n",
      "[51]\tvalid_0's binary_logloss: 0.268743\n",
      "0.05\n",
      "[52]\tvalid_0's binary_logloss: 0.268741\n",
      "0.05\n",
      "[53]\tvalid_0's binary_logloss: 0.268736\n",
      "0.05\n",
      "[54]\tvalid_0's binary_logloss: 0.268733\n",
      "0.05\n",
      "[55]\tvalid_0's binary_logloss: 0.268725\n",
      "0.05\n",
      "[56]\tvalid_0's binary_logloss: 0.268722\n",
      "0.05\n",
      "[57]\tvalid_0's binary_logloss: 0.268714\n",
      "0.05\n",
      "[58]\tvalid_0's binary_logloss: 0.268708\n",
      "0.05\n",
      "[59]\tvalid_0's binary_logloss: 0.268704\n",
      "0.05\n",
      "[60]\tvalid_0's binary_logloss: 0.268704\n",
      "0.05\n",
      "[61]\tvalid_0's binary_logloss: 0.268697\n",
      "0.05\n",
      "[62]\tvalid_0's binary_logloss: 0.268696\n",
      "0.05\n",
      "[63]\tvalid_0's binary_logloss: 0.268695\n",
      "0.05\n",
      "[64]\tvalid_0's binary_logloss: 0.268691\n",
      "0.05\n",
      "[65]\tvalid_0's binary_logloss: 0.268689\n",
      "0.05\n",
      "[66]\tvalid_0's binary_logloss: 0.268689\n",
      "0.05\n",
      "[67]\tvalid_0's binary_logloss: 0.268686\n",
      "0.05\n",
      "[68]\tvalid_0's binary_logloss: 0.268684\n",
      "0.05\n",
      "[69]\tvalid_0's binary_logloss: 0.268684\n",
      "0.05\n",
      "[70]\tvalid_0's binary_logloss: 0.26868\n",
      "0.05\n",
      "[71]\tvalid_0's binary_logloss: 0.268677\n",
      "0.05\n",
      "[72]\tvalid_0's binary_logloss: 0.268675\n",
      "0.05\n",
      "[73]\tvalid_0's binary_logloss: 0.268669\n",
      "0.05\n",
      "[74]\tvalid_0's binary_logloss: 0.268664\n",
      "0.05\n",
      "[75]\tvalid_0's binary_logloss: 0.268665\n",
      "0.05\n",
      "[76]\tvalid_0's binary_logloss: 0.268663\n",
      "0.05\n",
      "[77]\tvalid_0's binary_logloss: 0.268661\n",
      "0.05\n",
      "[78]\tvalid_0's binary_logloss: 0.268659\n",
      "0.05\n",
      "[79]\tvalid_0's binary_logloss: 0.268659\n",
      "0.05\n",
      "[80]\tvalid_0's binary_logloss: 0.268657\n",
      "0.05\n",
      "[81]\tvalid_0's binary_logloss: 0.268661\n",
      "0.05\n",
      "[82]\tvalid_0's binary_logloss: 0.26866\n",
      "0.05\n",
      "[83]\tvalid_0's binary_logloss: 0.268657\n",
      "0.05\n",
      "[84]\tvalid_0's binary_logloss: 0.26866\n",
      "0.05\n",
      "[85]\tvalid_0's binary_logloss: 0.26866\n",
      "0.05\n",
      "[86]\tvalid_0's binary_logloss: 0.268653\n",
      "0.05\n",
      "[87]\tvalid_0's binary_logloss: 0.268651\n",
      "0.05\n",
      "[88]\tvalid_0's binary_logloss: 0.268649\n",
      "0.05\n",
      "[89]\tvalid_0's binary_logloss: 0.26864\n",
      "0.05\n",
      "[90]\tvalid_0's binary_logloss: 0.268643\n",
      "0.05\n",
      "[91]\tvalid_0's binary_logloss: 0.26864\n",
      "0.05\n",
      "[92]\tvalid_0's binary_logloss: 0.268647\n",
      "0.05\n",
      "[93]\tvalid_0's binary_logloss: 0.268647\n",
      "0.05\n",
      "[94]\tvalid_0's binary_logloss: 0.268648\n",
      "0.05\n",
      "[95]\tvalid_0's binary_logloss: 0.268648\n",
      "0.05\n",
      "[96]\tvalid_0's binary_logloss: 0.26865\n",
      "0.05\n",
      "[97]\tvalid_0's binary_logloss: 0.268648\n",
      "0.05\n",
      "[98]\tvalid_0's binary_logloss: 0.268648\n",
      "0.05\n",
      "[99]\tvalid_0's binary_logloss: 0.268648\n",
      "0.05\n",
      "[100]\tvalid_0's binary_logloss: 0.268651\n",
      "0.03333333333333333\n",
      "[101]\tvalid_0's binary_logloss: 0.268649\n",
      "0.03333333333333333\n",
      "[102]\tvalid_0's binary_logloss: 0.268649\n",
      "0.03333333333333333\n",
      "[103]\tvalid_0's binary_logloss: 0.268649\n",
      "0.03333333333333333\n",
      "[104]\tvalid_0's binary_logloss: 0.268649\n",
      "0.03333333333333333\n",
      "[105]\tvalid_0's binary_logloss: 0.268647\n",
      "0.03333333333333333\n",
      "[106]\tvalid_0's binary_logloss: 0.268646\n",
      "0.03333333333333333\n",
      "[107]\tvalid_0's binary_logloss: 0.268648\n",
      "0.03333333333333333\n",
      "[108]\tvalid_0's binary_logloss: 0.268648\n",
      "0.03333333333333333\n",
      "[109]\tvalid_0's binary_logloss: 0.268647\n",
      "0.03333333333333333\n",
      "[110]\tvalid_0's binary_logloss: 0.268646\n",
      "0.03333333333333333\n",
      "[111]\tvalid_0's binary_logloss: 0.268642\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's binary_logloss: 0.26864\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree_index</th>\n",
       "      <th>node_depth</th>\n",
       "      <th>node_index</th>\n",
       "      <th>left_child</th>\n",
       "      <th>right_child</th>\n",
       "      <th>parent_index</th>\n",
       "      <th>split_feature</th>\n",
       "      <th>split_gain</th>\n",
       "      <th>threshold</th>\n",
       "      <th>decision_type</th>\n",
       "      <th>missing_direction</th>\n",
       "      <th>missing_type</th>\n",
       "      <th>value</th>\n",
       "      <th>weight</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0-S0</td>\n",
       "      <td>0-S1</td>\n",
       "      <td>0-L1</td>\n",
       "      <td>None</td>\n",
       "      <td>5萬捨てカウント</td>\n",
       "      <td>23658.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;=</td>\n",
       "      <td>left</td>\n",
       "      <td>None</td>\n",
       "      <td>-2.396230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1898544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0-S1</td>\n",
       "      <td>0-S2</td>\n",
       "      <td>0-S4</td>\n",
       "      <td>0-S0</td>\n",
       "      <td>8萬捨てカウント</td>\n",
       "      <td>5829.709961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;=</td>\n",
       "      <td>left</td>\n",
       "      <td>None</td>\n",
       "      <td>-2.381140</td>\n",
       "      <td>127413.000000</td>\n",
       "      <td>1665631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0-S2</td>\n",
       "      <td>0-S3</td>\n",
       "      <td>0-S7</td>\n",
       "      <td>0-S1</td>\n",
       "      <td>2萬捨てカウント</td>\n",
       "      <td>4428.419922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;=</td>\n",
       "      <td>left</td>\n",
       "      <td>None</td>\n",
       "      <td>-2.370170</td>\n",
       "      <td>100891.000000</td>\n",
       "      <td>1318918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0-S3</td>\n",
       "      <td>0-S6</td>\n",
       "      <td>0-S5</td>\n",
       "      <td>0-S2</td>\n",
       "      <td>捨牌8</td>\n",
       "      <td>3474.110107</td>\n",
       "      <td>0||3||7</td>\n",
       "      <td>==</td>\n",
       "      <td>right</td>\n",
       "      <td>None</td>\n",
       "      <td>-2.359470</td>\n",
       "      <td>80017.800000</td>\n",
       "      <td>1046051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0-S6</td>\n",
       "      <td>0-S14</td>\n",
       "      <td>0-S11</td>\n",
       "      <td>0-S3</td>\n",
       "      <td>捨牌5</td>\n",
       "      <td>829.322998</td>\n",
       "      <td>0||3||4||6||7</td>\n",
       "      <td>==</td>\n",
       "      <td>right</td>\n",
       "      <td>None</td>\n",
       "      <td>-2.379310</td>\n",
       "      <td>41993.100000</td>\n",
       "      <td>548964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5546</th>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "      <td>90-S20</td>\n",
       "      <td>90-S21</td>\n",
       "      <td>90-L21</td>\n",
       "      <td>90-S18</td>\n",
       "      <td>リーチ前0</td>\n",
       "      <td>19.968700</td>\n",
       "      <td>1||3||6||9||10||16||19||24||31||32</td>\n",
       "      <td>==</td>\n",
       "      <td>right</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.018456</td>\n",
       "      <td>217.551000</td>\n",
       "      <td>191163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>90</td>\n",
       "      <td>5</td>\n",
       "      <td>90-S21</td>\n",
       "      <td>90-L19</td>\n",
       "      <td>90-L22</td>\n",
       "      <td>90-S20</td>\n",
       "      <td>捨牌4</td>\n",
       "      <td>26.772499</td>\n",
       "      <td>1||2||3||5||15||16||19||22||23||24||25||26||27...</td>\n",
       "      <td>==</td>\n",
       "      <td>right</td>\n",
       "      <td>None</td>\n",
       "      <td>0.008491</td>\n",
       "      <td>51.430100</td>\n",
       "      <td>34154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5548</th>\n",
       "      <td>90</td>\n",
       "      <td>6</td>\n",
       "      <td>90-L19</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>90-S21</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.035370</td>\n",
       "      <td>29.192799</td>\n",
       "      <td>19304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5549</th>\n",
       "      <td>90</td>\n",
       "      <td>6</td>\n",
       "      <td>90-L22</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>90-S21</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.026821</td>\n",
       "      <td>22.237314</td>\n",
       "      <td>14850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5550</th>\n",
       "      <td>90</td>\n",
       "      <td>5</td>\n",
       "      <td>90-L21</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>90-S20</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.026808</td>\n",
       "      <td>166.121254</td>\n",
       "      <td>157009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5551 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tree_index  node_depth node_index left_child right_child parent_index  \\\n",
       "0              0           1       0-S0       0-S1        0-L1         None   \n",
       "1              0           2       0-S1       0-S2        0-S4         0-S0   \n",
       "2              0           3       0-S2       0-S3        0-S7         0-S1   \n",
       "3              0           4       0-S3       0-S6        0-S5         0-S2   \n",
       "4              0           5       0-S6      0-S14       0-S11         0-S3   \n",
       "...          ...         ...        ...        ...         ...          ...   \n",
       "5546          90           4     90-S20     90-S21      90-L21       90-S18   \n",
       "5547          90           5     90-S21     90-L19      90-L22       90-S20   \n",
       "5548          90           6     90-L19       None        None       90-S21   \n",
       "5549          90           6     90-L22       None        None       90-S21   \n",
       "5550          90           5     90-L21       None        None       90-S20   \n",
       "\n",
       "     split_feature    split_gain  \\\n",
       "0         5萬捨てカウント  23658.000000   \n",
       "1         8萬捨てカウント   5829.709961   \n",
       "2         2萬捨てカウント   4428.419922   \n",
       "3              捨牌8   3474.110107   \n",
       "4              捨牌5    829.322998   \n",
       "...            ...           ...   \n",
       "5546         リーチ前0     19.968700   \n",
       "5547           捨牌4     26.772499   \n",
       "5548          None           NaN   \n",
       "5549          None           NaN   \n",
       "5550          None           NaN   \n",
       "\n",
       "                                              threshold decision_type  \\\n",
       "0                                                   0.0            <=   \n",
       "1                                                   0.0            <=   \n",
       "2                                                   0.0            <=   \n",
       "3                                               0||3||7            ==   \n",
       "4                                         0||3||4||6||7            ==   \n",
       "...                                                 ...           ...   \n",
       "5546                 1||3||6||9||10||16||19||24||31||32            ==   \n",
       "5547  1||2||3||5||15||16||19||22||23||24||25||26||27...            ==   \n",
       "5548                                               None          None   \n",
       "5549                                               None          None   \n",
       "5550                                               None          None   \n",
       "\n",
       "     missing_direction missing_type     value         weight    count  \n",
       "0                 left         None -2.396230       0.000000  1898544  \n",
       "1                 left         None -2.381140  127413.000000  1665631  \n",
       "2                 left         None -2.370170  100891.000000  1318918  \n",
       "3                right         None -2.359470   80017.800000  1046051  \n",
       "4                right         None -2.379310   41993.100000   548964  \n",
       "...                ...          ...       ...            ...      ...  \n",
       "5546             right         None -0.018456     217.551000   191163  \n",
       "5547             right         None  0.008491      51.430100    34154  \n",
       "5548              None         None  0.035370      29.192799    19304  \n",
       "5549              None         None -0.026821      22.237314    14850  \n",
       "5550              None         None -0.026808     166.121254   157009  \n",
       "\n",
       "[5551 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps = 1\n",
    "def helper(n):\n",
    "    k = n//50\n",
    "    r = 0.1 / (k+1)\n",
    "    print(r)\n",
    "    return r\n",
    "train_and_test('data/featurized', early_stopping_rounds=20, num_boost_round=1000, learning_rates=helper, verbose_eval=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bad1ef1f-59d5-431f-80d5-4782d1ff20c5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hahho\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\basic.py:1705: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['捨牌1', '捨牌10', '捨牌11', '捨牌12', '捨牌13', '捨牌14', '捨牌15', '捨牌16', '捨牌17', '捨牌18', '捨牌19', '捨牌2', '捨牌20', '捨牌3', '捨牌4', '捨牌5', '捨牌6', '捨牌7', '捨牌8', '捨牌9']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2837988, number of negative: 31335804\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.245696 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 626\n",
      "[LightGBM] [Info] Number of data points in the train set: 34173792, number of used features: 20\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hahho\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "c:\\users\\hahho\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.083046 -> initscore=-2.401666\n",
      "[LightGBM] [Info] Start training from score -2.401666\n",
      "[1]\tvalid_0's binary_logloss: 0.283759\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "0.1\n",
      "[2]\tvalid_0's binary_logloss: 0.282294\n",
      "0.1\n",
      "[3]\tvalid_0's binary_logloss: 0.281051\n",
      "0.1\n",
      "[4]\tvalid_0's binary_logloss: 0.279942\n",
      "0.1\n",
      "[5]\tvalid_0's binary_logloss: 0.278982\n",
      "0.1\n",
      "[6]\tvalid_0's binary_logloss: 0.278111\n",
      "0.1\n",
      "[7]\tvalid_0's binary_logloss: 0.277339\n",
      "0.1\n",
      "[8]\tvalid_0's binary_logloss: 0.276637\n",
      "0.1\n",
      "[9]\tvalid_0's binary_logloss: 0.276002\n",
      "0.1\n",
      "[10]\tvalid_0's binary_logloss: 0.275446\n",
      "0.1\n",
      "[11]\tvalid_0's binary_logloss: 0.274924\n",
      "0.1\n",
      "[12]\tvalid_0's binary_logloss: 0.274468\n",
      "0.1\n",
      "[13]\tvalid_0's binary_logloss: 0.274051\n",
      "0.1\n",
      "[14]\tvalid_0's binary_logloss: 0.273672\n",
      "0.1\n",
      "[15]\tvalid_0's binary_logloss: 0.273289\n",
      "0.1\n",
      "[16]\tvalid_0's binary_logloss: 0.272976\n",
      "0.1\n",
      "[17]\tvalid_0's binary_logloss: 0.272705\n",
      "0.1\n",
      "[18]\tvalid_0's binary_logloss: 0.272436\n",
      "0.1\n",
      "[19]\tvalid_0's binary_logloss: 0.272188\n",
      "0.1\n",
      "[20]\tvalid_0's binary_logloss: 0.271976\n",
      "0.1\n",
      "[21]\tvalid_0's binary_logloss: 0.271789\n",
      "0.1\n",
      "[22]\tvalid_0's binary_logloss: 0.271594\n",
      "0.1\n",
      "[23]\tvalid_0's binary_logloss: 0.271431\n",
      "0.1\n",
      "[24]\tvalid_0's binary_logloss: 0.271278\n",
      "0.1\n",
      "[25]\tvalid_0's binary_logloss: 0.271146\n",
      "0.1\n",
      "[26]\tvalid_0's binary_logloss: 0.271028\n",
      "0.1\n",
      "[27]\tvalid_0's binary_logloss: 0.270907\n",
      "0.1\n",
      "[28]\tvalid_0's binary_logloss: 0.27081\n",
      "0.1\n",
      "[29]\tvalid_0's binary_logloss: 0.270716\n",
      "0.1\n",
      "[30]\tvalid_0's binary_logloss: 0.270635\n",
      "0.1\n",
      "[31]\tvalid_0's binary_logloss: 0.270559\n",
      "0.1\n",
      "[32]\tvalid_0's binary_logloss: 0.270487\n",
      "0.1\n",
      "[33]\tvalid_0's binary_logloss: 0.270417\n",
      "0.1\n",
      "[34]\tvalid_0's binary_logloss: 0.270358\n",
      "0.1\n",
      "[35]\tvalid_0's binary_logloss: 0.270295\n",
      "0.1\n",
      "[36]\tvalid_0's binary_logloss: 0.270253\n",
      "0.1\n",
      "[37]\tvalid_0's binary_logloss: 0.270199\n",
      "0.1\n",
      "[38]\tvalid_0's binary_logloss: 0.270146\n",
      "0.1\n",
      "[39]\tvalid_0's binary_logloss: 0.270112\n",
      "0.1\n",
      "[40]\tvalid_0's binary_logloss: 0.270074\n",
      "0.1\n",
      "[41]\tvalid_0's binary_logloss: 0.270033\n",
      "0.1\n",
      "[42]\tvalid_0's binary_logloss: 0.27\n",
      "0.1\n",
      "[43]\tvalid_0's binary_logloss: 0.269972\n",
      "0.1\n",
      "[44]\tvalid_0's binary_logloss: 0.269937\n",
      "0.1\n",
      "[45]\tvalid_0's binary_logloss: 0.269904\n",
      "0.1\n",
      "[46]\tvalid_0's binary_logloss: 0.269874\n",
      "0.1\n",
      "[47]\tvalid_0's binary_logloss: 0.269853\n",
      "0.1\n",
      "[48]\tvalid_0's binary_logloss: 0.269836\n",
      "0.1\n",
      "[49]\tvalid_0's binary_logloss: 0.26982\n",
      "0.1\n",
      "[50]\tvalid_0's binary_logloss: 0.269796\n",
      "0.05\n",
      "[51]\tvalid_0's binary_logloss: 0.269786\n",
      "0.05\n",
      "[52]\tvalid_0's binary_logloss: 0.269776\n",
      "0.05\n",
      "[53]\tvalid_0's binary_logloss: 0.269766\n",
      "0.05\n",
      "[54]\tvalid_0's binary_logloss: 0.26976\n",
      "0.05\n",
      "[55]\tvalid_0's binary_logloss: 0.26975\n",
      "0.05\n",
      "[56]\tvalid_0's binary_logloss: 0.269742\n",
      "0.05\n",
      "[57]\tvalid_0's binary_logloss: 0.269736\n",
      "0.05\n",
      "[58]\tvalid_0's binary_logloss: 0.269726\n",
      "0.05\n",
      "[59]\tvalid_0's binary_logloss: 0.269716\n",
      "0.05\n",
      "[60]\tvalid_0's binary_logloss: 0.269707\n",
      "0.05\n",
      "[61]\tvalid_0's binary_logloss: 0.269696\n",
      "0.05\n",
      "[62]\tvalid_0's binary_logloss: 0.269687\n",
      "0.05\n",
      "[63]\tvalid_0's binary_logloss: 0.269681\n",
      "0.05\n",
      "[64]\tvalid_0's binary_logloss: 0.269675\n",
      "0.05\n",
      "[65]\tvalid_0's binary_logloss: 0.269666\n",
      "0.05\n",
      "[66]\tvalid_0's binary_logloss: 0.269658\n",
      "0.05\n",
      "[67]\tvalid_0's binary_logloss: 0.26965\n",
      "0.05\n",
      "[68]\tvalid_0's binary_logloss: 0.269645\n",
      "0.05\n",
      "[69]\tvalid_0's binary_logloss: 0.269638\n",
      "0.05\n",
      "[70]\tvalid_0's binary_logloss: 0.269634\n",
      "0.05\n",
      "[71]\tvalid_0's binary_logloss: 0.269627\n",
      "0.05\n",
      "[72]\tvalid_0's binary_logloss: 0.269623\n",
      "0.05\n",
      "[73]\tvalid_0's binary_logloss: 0.269619\n",
      "0.05\n",
      "[74]\tvalid_0's binary_logloss: 0.269614\n",
      "0.05\n",
      "[75]\tvalid_0's binary_logloss: 0.269609\n",
      "0.05\n",
      "[76]\tvalid_0's binary_logloss: 0.269606\n",
      "0.05\n",
      "[77]\tvalid_0's binary_logloss: 0.269603\n",
      "0.05\n",
      "[78]\tvalid_0's binary_logloss: 0.269597\n",
      "0.05\n",
      "[79]\tvalid_0's binary_logloss: 0.269594\n",
      "0.05\n",
      "[80]\tvalid_0's binary_logloss: 0.269589\n",
      "0.05\n",
      "[81]\tvalid_0's binary_logloss: 0.269586\n",
      "0.05\n",
      "[82]\tvalid_0's binary_logloss: 0.269583\n",
      "0.05\n",
      "[83]\tvalid_0's binary_logloss: 0.269577\n",
      "0.05\n",
      "[84]\tvalid_0's binary_logloss: 0.269574\n",
      "0.05\n",
      "[85]\tvalid_0's binary_logloss: 0.269571\n",
      "0.05\n",
      "[86]\tvalid_0's binary_logloss: 0.269568\n",
      "0.05\n",
      "[87]\tvalid_0's binary_logloss: 0.269563\n",
      "0.05\n",
      "[88]\tvalid_0's binary_logloss: 0.269562\n",
      "0.05\n",
      "[89]\tvalid_0's binary_logloss: 0.269558\n",
      "0.05\n",
      "[90]\tvalid_0's binary_logloss: 0.269555\n",
      "0.05\n",
      "[91]\tvalid_0's binary_logloss: 0.269551\n",
      "0.05\n",
      "[92]\tvalid_0's binary_logloss: 0.269546\n",
      "0.05\n",
      "[93]\tvalid_0's binary_logloss: 0.269542\n",
      "0.05\n",
      "[94]\tvalid_0's binary_logloss: 0.26954\n",
      "0.05\n",
      "[95]\tvalid_0's binary_logloss: 0.269535\n",
      "0.05\n",
      "[96]\tvalid_0's binary_logloss: 0.269533\n",
      "0.05\n",
      "[97]\tvalid_0's binary_logloss: 0.269533\n",
      "0.05\n",
      "[98]\tvalid_0's binary_logloss: 0.269529\n",
      "0.05\n",
      "[99]\tvalid_0's binary_logloss: 0.269525\n",
      "0.05\n",
      "[100]\tvalid_0's binary_logloss: 0.26952\n",
      "0.03333333333333333\n",
      "[101]\tvalid_0's binary_logloss: 0.269517\n",
      "0.03333333333333333\n",
      "[102]\tvalid_0's binary_logloss: 0.269516\n",
      "0.03333333333333333\n",
      "[103]\tvalid_0's binary_logloss: 0.269516\n",
      "0.03333333333333333\n",
      "[104]\tvalid_0's binary_logloss: 0.269514\n",
      "0.03333333333333333\n",
      "[105]\tvalid_0's binary_logloss: 0.269513\n",
      "0.03333333333333333\n",
      "[106]\tvalid_0's binary_logloss: 0.269512\n",
      "0.03333333333333333\n",
      "[107]\tvalid_0's binary_logloss: 0.26951\n",
      "0.03333333333333333\n",
      "[108]\tvalid_0's binary_logloss: 0.269509\n",
      "0.03333333333333333\n",
      "[109]\tvalid_0's binary_logloss: 0.269508\n",
      "0.03333333333333333\n",
      "[110]\tvalid_0's binary_logloss: 0.269507\n",
      "0.03333333333333333\n",
      "[111]\tvalid_0's binary_logloss: 0.269506\n",
      "0.03333333333333333\n",
      "[112]\tvalid_0's binary_logloss: 0.269503\n",
      "0.03333333333333333\n",
      "[113]\tvalid_0's binary_logloss: 0.269503\n",
      "0.03333333333333333\n",
      "[114]\tvalid_0's binary_logloss: 0.269499\n",
      "0.03333333333333333\n",
      "[115]\tvalid_0's binary_logloss: 0.269498\n",
      "0.03333333333333333\n",
      "[116]\tvalid_0's binary_logloss: 0.269496\n",
      "0.03333333333333333\n",
      "[117]\tvalid_0's binary_logloss: 0.269496\n",
      "0.03333333333333333\n",
      "[118]\tvalid_0's binary_logloss: 0.269496\n",
      "0.03333333333333333\n",
      "[119]\tvalid_0's binary_logloss: 0.269495\n",
      "0.03333333333333333\n",
      "[120]\tvalid_0's binary_logloss: 0.269495\n",
      "0.03333333333333333\n",
      "[121]\tvalid_0's binary_logloss: 0.269494\n",
      "0.03333333333333333\n",
      "[122]\tvalid_0's binary_logloss: 0.269494\n",
      "0.03333333333333333\n",
      "[123]\tvalid_0's binary_logloss: 0.269494\n",
      "0.03333333333333333\n",
      "[124]\tvalid_0's binary_logloss: 0.269492\n",
      "0.03333333333333333\n",
      "[125]\tvalid_0's binary_logloss: 0.269491\n",
      "0.03333333333333333\n",
      "[126]\tvalid_0's binary_logloss: 0.26949\n",
      "0.03333333333333333\n",
      "[127]\tvalid_0's binary_logloss: 0.26949\n",
      "0.03333333333333333\n",
      "[128]\tvalid_0's binary_logloss: 0.26949\n",
      "0.03333333333333333\n",
      "[129]\tvalid_0's binary_logloss: 0.269489\n",
      "0.03333333333333333\n",
      "[130]\tvalid_0's binary_logloss: 0.269488\n",
      "0.03333333333333333\n",
      "[131]\tvalid_0's binary_logloss: 0.269486\n",
      "0.03333333333333333\n",
      "[132]\tvalid_0's binary_logloss: 0.269485\n",
      "0.03333333333333333\n",
      "[133]\tvalid_0's binary_logloss: 0.269485\n",
      "0.03333333333333333\n",
      "[134]\tvalid_0's binary_logloss: 0.269484\n",
      "0.03333333333333333\n",
      "[135]\tvalid_0's binary_logloss: 0.269483\n",
      "0.03333333333333333\n",
      "[136]\tvalid_0's binary_logloss: 0.269481\n",
      "0.03333333333333333\n",
      "[137]\tvalid_0's binary_logloss: 0.26948\n",
      "0.03333333333333333\n",
      "[138]\tvalid_0's binary_logloss: 0.269479\n",
      "0.03333333333333333\n",
      "[139]\tvalid_0's binary_logloss: 0.269479\n",
      "0.03333333333333333\n",
      "[140]\tvalid_0's binary_logloss: 0.269479\n",
      "0.03333333333333333\n",
      "[141]\tvalid_0's binary_logloss: 0.26948\n",
      "0.03333333333333333\n",
      "[142]\tvalid_0's binary_logloss: 0.269479\n",
      "0.03333333333333333\n",
      "[143]\tvalid_0's binary_logloss: 0.269479\n",
      "0.03333333333333333\n",
      "[144]\tvalid_0's binary_logloss: 0.269474\n",
      "0.03333333333333333\n",
      "[145]\tvalid_0's binary_logloss: 0.269474\n",
      "0.03333333333333333\n",
      "[146]\tvalid_0's binary_logloss: 0.269473\n",
      "0.03333333333333333\n",
      "[147]\tvalid_0's binary_logloss: 0.269471\n",
      "0.03333333333333333\n",
      "[148]\tvalid_0's binary_logloss: 0.269471\n",
      "0.03333333333333333\n",
      "[149]\tvalid_0's binary_logloss: 0.269468\n",
      "0.03333333333333333\n",
      "[150]\tvalid_0's binary_logloss: 0.269468\n",
      "0.025\n",
      "[151]\tvalid_0's binary_logloss: 0.269469\n",
      "0.025\n",
      "[152]\tvalid_0's binary_logloss: 0.269469\n",
      "0.025\n",
      "[153]\tvalid_0's binary_logloss: 0.269468\n",
      "0.025\n",
      "[154]\tvalid_0's binary_logloss: 0.269468\n",
      "0.025\n",
      "[155]\tvalid_0's binary_logloss: 0.269467\n",
      "0.025\n",
      "[156]\tvalid_0's binary_logloss: 0.269466\n",
      "0.025\n",
      "[157]\tvalid_0's binary_logloss: 0.269466\n",
      "0.025\n",
      "[158]\tvalid_0's binary_logloss: 0.269466\n",
      "0.025\n",
      "[159]\tvalid_0's binary_logloss: 0.269466\n",
      "0.025\n",
      "[160]\tvalid_0's binary_logloss: 0.269466\n",
      "0.025\n",
      "[161]\tvalid_0's binary_logloss: 0.269466\n",
      "0.025\n",
      "[162]\tvalid_0's binary_logloss: 0.269465\n",
      "0.025\n",
      "[163]\tvalid_0's binary_logloss: 0.269466\n",
      "0.025\n",
      "[164]\tvalid_0's binary_logloss: 0.269466\n",
      "0.025\n",
      "[165]\tvalid_0's binary_logloss: 0.269466\n",
      "0.025\n",
      "[166]\tvalid_0's binary_logloss: 0.269465\n",
      "0.025\n",
      "[167]\tvalid_0's binary_logloss: 0.269465\n",
      "0.025\n",
      "[168]\tvalid_0's binary_logloss: 0.269465\n",
      "0.025\n",
      "[169]\tvalid_0's binary_logloss: 0.269465\n",
      "0.025\n",
      "[170]\tvalid_0's binary_logloss: 0.269465\n",
      "0.025\n",
      "[171]\tvalid_0's binary_logloss: 0.269464\n",
      "0.025\n",
      "[172]\tvalid_0's binary_logloss: 0.269462\n",
      "0.025\n",
      "[173]\tvalid_0's binary_logloss: 0.269462\n",
      "0.025\n",
      "[174]\tvalid_0's binary_logloss: 0.269461\n",
      "0.025\n",
      "[175]\tvalid_0's binary_logloss: 0.26946\n",
      "0.025\n",
      "[176]\tvalid_0's binary_logloss: 0.26946\n",
      "0.025\n",
      "[177]\tvalid_0's binary_logloss: 0.26946\n",
      "0.025\n",
      "[178]\tvalid_0's binary_logloss: 0.26946\n",
      "0.025\n",
      "[179]\tvalid_0's binary_logloss: 0.269459\n",
      "0.025\n",
      "[180]\tvalid_0's binary_logloss: 0.269458\n",
      "0.025\n",
      "[181]\tvalid_0's binary_logloss: 0.269457\n",
      "0.025\n",
      "[182]\tvalid_0's binary_logloss: 0.269456\n",
      "0.025\n",
      "[183]\tvalid_0's binary_logloss: 0.269456\n",
      "0.025\n",
      "[184]\tvalid_0's binary_logloss: 0.269456\n",
      "0.025\n",
      "[185]\tvalid_0's binary_logloss: 0.269456\n",
      "0.025\n",
      "[186]\tvalid_0's binary_logloss: 0.269456\n",
      "0.025\n",
      "[187]\tvalid_0's binary_logloss: 0.269456\n",
      "0.025\n",
      "[188]\tvalid_0's binary_logloss: 0.269456\n",
      "0.025\n",
      "[189]\tvalid_0's binary_logloss: 0.269455\n",
      "0.025\n",
      "[190]\tvalid_0's binary_logloss: 0.269456\n",
      "0.025\n",
      "[191]\tvalid_0's binary_logloss: 0.269455\n",
      "0.025\n",
      "[192]\tvalid_0's binary_logloss: 0.269455\n",
      "0.025\n",
      "[193]\tvalid_0's binary_logloss: 0.269454\n",
      "0.025\n",
      "[194]\tvalid_0's binary_logloss: 0.269453\n",
      "0.025\n",
      "[195]\tvalid_0's binary_logloss: 0.269454\n",
      "0.025\n",
      "[196]\tvalid_0's binary_logloss: 0.269451\n",
      "0.025\n",
      "[197]\tvalid_0's binary_logloss: 0.269452\n",
      "0.025\n",
      "[198]\tvalid_0's binary_logloss: 0.269451\n",
      "0.025\n",
      "[199]\tvalid_0's binary_logloss: 0.26945\n",
      "0.025\n",
      "[200]\tvalid_0's binary_logloss: 0.26945\n",
      "0.02\n",
      "[201]\tvalid_0's binary_logloss: 0.26945\n",
      "0.02\n",
      "[202]\tvalid_0's binary_logloss: 0.26945\n",
      "0.02\n",
      "[203]\tvalid_0's binary_logloss: 0.26945\n",
      "0.02\n",
      "[204]\tvalid_0's binary_logloss: 0.26945\n",
      "0.02\n",
      "[205]\tvalid_0's binary_logloss: 0.26945\n",
      "0.02\n",
      "[206]\tvalid_0's binary_logloss: 0.269448\n",
      "0.02\n",
      "[207]\tvalid_0's binary_logloss: 0.269448\n",
      "0.02\n",
      "[208]\tvalid_0's binary_logloss: 0.269447\n",
      "0.02\n",
      "[209]\tvalid_0's binary_logloss: 0.269447\n",
      "0.02\n",
      "[210]\tvalid_0's binary_logloss: 0.269447\n",
      "0.02\n",
      "[211]\tvalid_0's binary_logloss: 0.269448\n",
      "0.02\n",
      "[212]\tvalid_0's binary_logloss: 0.269448\n",
      "0.02\n",
      "[213]\tvalid_0's binary_logloss: 0.269448\n",
      "0.02\n",
      "[214]\tvalid_0's binary_logloss: 0.269448\n",
      "0.02\n",
      "[215]\tvalid_0's binary_logloss: 0.269447\n",
      "0.02\n",
      "[216]\tvalid_0's binary_logloss: 0.269448\n",
      "0.02\n",
      "[217]\tvalid_0's binary_logloss: 0.269447\n",
      "0.02\n",
      "[218]\tvalid_0's binary_logloss: 0.269447\n",
      "0.02\n",
      "[219]\tvalid_0's binary_logloss: 0.269447\n",
      "0.02\n",
      "[220]\tvalid_0's binary_logloss: 0.269447\n",
      "0.02\n",
      "[221]\tvalid_0's binary_logloss: 0.269446\n",
      "0.02\n",
      "[222]\tvalid_0's binary_logloss: 0.269446\n",
      "0.02\n",
      "[223]\tvalid_0's binary_logloss: 0.269446\n",
      "0.02\n",
      "[224]\tvalid_0's binary_logloss: 0.269447\n",
      "0.02\n",
      "[225]\tvalid_0's binary_logloss: 0.269446\n",
      "0.02\n",
      "[226]\tvalid_0's binary_logloss: 0.269446\n",
      "0.02\n",
      "[227]\tvalid_0's binary_logloss: 0.269446\n",
      "0.02\n",
      "[228]\tvalid_0's binary_logloss: 0.269446\n",
      "0.02\n",
      "[229]\tvalid_0's binary_logloss: 0.269445\n",
      "0.02\n",
      "[230]\tvalid_0's binary_logloss: 0.269445\n",
      "0.02\n",
      "[231]\tvalid_0's binary_logloss: 0.269443\n",
      "0.02\n",
      "[232]\tvalid_0's binary_logloss: 0.269443\n",
      "0.02\n",
      "[233]\tvalid_0's binary_logloss: 0.269443\n",
      "0.02\n",
      "[234]\tvalid_0's binary_logloss: 0.269443\n",
      "0.02\n",
      "[235]\tvalid_0's binary_logloss: 0.269443\n",
      "0.02\n",
      "[236]\tvalid_0's binary_logloss: 0.269442\n",
      "0.02\n",
      "[237]\tvalid_0's binary_logloss: 0.269442\n",
      "0.02\n",
      "[238]\tvalid_0's binary_logloss: 0.269442\n",
      "0.02\n",
      "[239]\tvalid_0's binary_logloss: 0.269441\n",
      "0.02\n",
      "[240]\tvalid_0's binary_logloss: 0.26944\n",
      "0.02\n",
      "[241]\tvalid_0's binary_logloss: 0.26944\n",
      "0.02\n",
      "[242]\tvalid_0's binary_logloss: 0.269439\n",
      "0.02\n",
      "[243]\tvalid_0's binary_logloss: 0.269438\n",
      "0.02\n",
      "[244]\tvalid_0's binary_logloss: 0.269438\n",
      "0.02\n",
      "[245]\tvalid_0's binary_logloss: 0.269438\n",
      "0.02\n",
      "[246]\tvalid_0's binary_logloss: 0.269438\n",
      "0.02\n",
      "[247]\tvalid_0's binary_logloss: 0.269437\n",
      "0.02\n",
      "[248]\tvalid_0's binary_logloss: 0.269436\n",
      "0.02\n",
      "[249]\tvalid_0's binary_logloss: 0.269436\n",
      "0.02\n",
      "[250]\tvalid_0's binary_logloss: 0.269436\n",
      "0.016666666666666666\n",
      "[251]\tvalid_0's binary_logloss: 0.269435\n",
      "0.016666666666666666\n",
      "[252]\tvalid_0's binary_logloss: 0.269436\n",
      "0.016666666666666666\n",
      "[253]\tvalid_0's binary_logloss: 0.269436\n",
      "0.016666666666666666\n",
      "[254]\tvalid_0's binary_logloss: 0.269436\n",
      "0.016666666666666666\n",
      "[255]\tvalid_0's binary_logloss: 0.269436\n",
      "0.016666666666666666\n",
      "[256]\tvalid_0's binary_logloss: 0.269436\n",
      "0.016666666666666666\n",
      "[257]\tvalid_0's binary_logloss: 0.269436\n",
      "0.016666666666666666\n",
      "[258]\tvalid_0's binary_logloss: 0.269436\n",
      "0.016666666666666666\n",
      "[259]\tvalid_0's binary_logloss: 0.269437\n",
      "0.016666666666666666\n",
      "[260]\tvalid_0's binary_logloss: 0.269437\n",
      "0.016666666666666666\n",
      "[261]\tvalid_0's binary_logloss: 0.269436\n",
      "0.016666666666666666\n",
      "[262]\tvalid_0's binary_logloss: 0.269436\n",
      "0.016666666666666666\n",
      "[263]\tvalid_0's binary_logloss: 0.269436\n",
      "0.016666666666666666\n",
      "[264]\tvalid_0's binary_logloss: 0.269436\n",
      "0.016666666666666666\n",
      "[265]\tvalid_0's binary_logloss: 0.269436\n",
      "0.016666666666666666\n",
      "[266]\tvalid_0's binary_logloss: 0.269436\n",
      "0.016666666666666666\n",
      "[267]\tvalid_0's binary_logloss: 0.269437\n",
      "0.016666666666666666\n",
      "[268]\tvalid_0's binary_logloss: 0.269436\n",
      "0.016666666666666666\n",
      "[269]\tvalid_0's binary_logloss: 0.269436\n",
      "0.016666666666666666\n",
      "[270]\tvalid_0's binary_logloss: 0.269436\n",
      "0.016666666666666666\n",
      "[271]\tvalid_0's binary_logloss: 0.269436\n",
      "Early stopping, best iteration is:\n",
      "[251]\tvalid_0's binary_logloss: 0.269435\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree_index</th>\n",
       "      <th>node_depth</th>\n",
       "      <th>node_index</th>\n",
       "      <th>left_child</th>\n",
       "      <th>right_child</th>\n",
       "      <th>parent_index</th>\n",
       "      <th>split_feature</th>\n",
       "      <th>split_gain</th>\n",
       "      <th>threshold</th>\n",
       "      <th>decision_type</th>\n",
       "      <th>missing_direction</th>\n",
       "      <th>missing_type</th>\n",
       "      <th>value</th>\n",
       "      <th>weight</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0-S0</td>\n",
       "      <td>0-S12</td>\n",
       "      <td>0-S1</td>\n",
       "      <td>None</td>\n",
       "      <td>捨牌5</td>\n",
       "      <td>62689.500000</td>\n",
       "      <td>2||5||8</td>\n",
       "      <td>==</td>\n",
       "      <td>right</td>\n",
       "      <td>None</td>\n",
       "      <td>-2.401670</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>34173792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0-S12</td>\n",
       "      <td>0-L0</td>\n",
       "      <td>0-L13</td>\n",
       "      <td>0-S0</td>\n",
       "      <td>捨牌5</td>\n",
       "      <td>15244.599609</td>\n",
       "      <td>2||8</td>\n",
       "      <td>==</td>\n",
       "      <td>right</td>\n",
       "      <td>None</td>\n",
       "      <td>-2.454720</td>\n",
       "      <td>2.051760e+05</td>\n",
       "      <td>2694396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0-L0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0-S12</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-2.441068</td>\n",
       "      <td>1.640755e+05</td>\n",
       "      <td>2154660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0-L13</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0-S12</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-2.509178</td>\n",
       "      <td>4.110044e+04</td>\n",
       "      <td>539736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0-S1</td>\n",
       "      <td>0-S11</td>\n",
       "      <td>0-S2</td>\n",
       "      <td>0-S0</td>\n",
       "      <td>捨牌6</td>\n",
       "      <td>61214.199219</td>\n",
       "      <td>2||5||8</td>\n",
       "      <td>==</td>\n",
       "      <td>right</td>\n",
       "      <td>None</td>\n",
       "      <td>-2.397130</td>\n",
       "      <td>2.397130e+06</td>\n",
       "      <td>31479396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15306</th>\n",
       "      <td>250</td>\n",
       "      <td>5</td>\n",
       "      <td>250-S28</td>\n",
       "      <td>250-S29</td>\n",
       "      <td>250-L29</td>\n",
       "      <td>250-S15</td>\n",
       "      <td>捨牌5</td>\n",
       "      <td>100.550003</td>\n",
       "      <td>5||7||8</td>\n",
       "      <td>==</td>\n",
       "      <td>right</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>9.588210e+05</td>\n",
       "      <td>12722733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15307</th>\n",
       "      <td>250</td>\n",
       "      <td>6</td>\n",
       "      <td>250-S29</td>\n",
       "      <td>250-L16</td>\n",
       "      <td>250-L30</td>\n",
       "      <td>250-S28</td>\n",
       "      <td>捨牌6</td>\n",
       "      <td>470.687988</td>\n",
       "      <td>2||3||4||5</td>\n",
       "      <td>==</td>\n",
       "      <td>right</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.000866</td>\n",
       "      <td>4.131170e+04</td>\n",
       "      <td>907242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15308</th>\n",
       "      <td>250</td>\n",
       "      <td>7</td>\n",
       "      <td>250-L16</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>250-S29</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.007370</td>\n",
       "      <td>2.866549e+03</td>\n",
       "      <td>95988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15309</th>\n",
       "      <td>250</td>\n",
       "      <td>7</td>\n",
       "      <td>250-L30</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>250-S29</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.000380</td>\n",
       "      <td>3.844512e+04</td>\n",
       "      <td>811254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15310</th>\n",
       "      <td>250</td>\n",
       "      <td>6</td>\n",
       "      <td>250-L29</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>250-S28</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>9.175092e+05</td>\n",
       "      <td>11815491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15311 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tree_index  node_depth node_index left_child right_child parent_index  \\\n",
       "0               0           1       0-S0      0-S12        0-S1         None   \n",
       "1               0           2      0-S12       0-L0       0-L13         0-S0   \n",
       "2               0           3       0-L0       None        None        0-S12   \n",
       "3               0           3      0-L13       None        None        0-S12   \n",
       "4               0           2       0-S1      0-S11        0-S2         0-S0   \n",
       "...           ...         ...        ...        ...         ...          ...   \n",
       "15306         250           5    250-S28    250-S29     250-L29      250-S15   \n",
       "15307         250           6    250-S29    250-L16     250-L30      250-S28   \n",
       "15308         250           7    250-L16       None        None      250-S29   \n",
       "15309         250           7    250-L30       None        None      250-S29   \n",
       "15310         250           6    250-L29       None        None      250-S28   \n",
       "\n",
       "      split_feature    split_gain   threshold decision_type missing_direction  \\\n",
       "0               捨牌5  62689.500000     2||5||8            ==             right   \n",
       "1               捨牌5  15244.599609        2||8            ==             right   \n",
       "2              None           NaN        None          None              None   \n",
       "3              None           NaN        None          None              None   \n",
       "4               捨牌6  61214.199219     2||5||8            ==             right   \n",
       "...             ...           ...         ...           ...               ...   \n",
       "15306           捨牌5    100.550003     5||7||8            ==             right   \n",
       "15307           捨牌6    470.687988  2||3||4||5            ==             right   \n",
       "15308          None           NaN        None          None              None   \n",
       "15309          None           NaN        None          None              None   \n",
       "15310          None           NaN        None          None              None   \n",
       "\n",
       "      missing_type     value        weight     count  \n",
       "0             None -2.401670  0.000000e+00  34173792  \n",
       "1             None -2.454720  2.051760e+05   2694396  \n",
       "2             None -2.441068  1.640755e+05   2154660  \n",
       "3             None -2.509178  4.110044e+04    539736  \n",
       "4             None -2.397130  2.397130e+06  31479396  \n",
       "...            ...       ...           ...       ...  \n",
       "15306         None -0.000062  9.588210e+05  12722733  \n",
       "15307         None -0.000866  4.131170e+04    907242  \n",
       "15308         None -0.007370  2.866549e+03     95988  \n",
       "15309         None -0.000380  3.844512e+04    811254  \n",
       "15310         None -0.000026  9.175092e+05  11815491  \n",
       "\n",
       "[15311 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps = 1\n",
    "def helper(n):\n",
    "    k = n//50\n",
    "    r = 0.1 / (k+1)\n",
    "    print(r)\n",
    "    return r\n",
    "train_and_test('data/augmented', early_stopping_rounds=20, num_boost_round=1000, learning_rates=helper, verbose_eval=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cff6168-dac3-4cd0-8676-3e1c24afbdc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TILES = [f'{i+1}萬' for i in range(9)] + list('東南西北白')\n",
    "WAITS = [f'{t}待' for t in TILES]\n",
    "\n",
    "def train_and_save(data_dir, **train_params):\n",
    "    \n",
    "    models = {}\n",
    "    if 'params' in train_params:\n",
    "        pp = train_params['params']\n",
    "        del train_params['params']\n",
    "    else:\n",
    "        pp = {}\n",
    "    \n",
    "    \n",
    "    td = pd.read_feather(os.path.join(data_dir, 'train-data.feather'))\n",
    "    vd = pd.read_feather(os.path.join(data_dir, 'validation-data.feather'))\n",
    "    train_dataset = lg.Dataset(td)\n",
    "    valid_dataset = lg.Dataset(vd)\n",
    "    if 'リーチ前0' in td:\n",
    "        categoricals = [f'捨牌{i+1}' for i in range(20)] + [f'リーチ前{i}' for i in range(20)]\n",
    "    else:\n",
    "        categoricals = [f'捨牌{i+1}' for i in range(20)]\n",
    "    del td, vd\n",
    "    gc.collect()\n",
    "\n",
    "    tl = pd.read_feather(os.path.join(data_dir, 'train-label.feather'))\n",
    "    vl = pd.read_feather(os.path.join(data_dir, 'validation-label.feather'))\n",
    "    \n",
    "    \n",
    "    for i, tile in enumerate(WAITS):\n",
    "        train_dataset.set_label(tl[tile])\n",
    "        valid_dataset.set_label(vl[tile])\n",
    "        params = {\n",
    "            'objective': 'binary',}\n",
    "        params.update(pp)\n",
    "        model = lg.train(train_set=train_dataset,\n",
    "                         valid_sets=[valid_dataset],\n",
    "                         categorical_feature=categoricals,\n",
    "                         params=params,\n",
    "                         **train_params)\n",
    "        model.save_model(f'models/{i}.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddd68c18-e720-4d66-856f-b09a98faa409",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hahho\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\basic.py:1705: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['リーチ前0', 'リーチ前1', 'リーチ前10', 'リーチ前11', 'リーチ前12', 'リーチ前13', 'リーチ前14', 'リーチ前15', 'リーチ前16', 'リーチ前17', 'リーチ前18', 'リーチ前19', 'リーチ前2', 'リーチ前3', 'リーチ前4', 'リーチ前5', 'リーチ前6', 'リーチ前7', 'リーチ前8', 'リーチ前9', '捨牌1', '捨牌10', '捨牌11', '捨牌12', '捨牌13', '捨牌14', '捨牌15', '捨牌16', '捨牌17', '捨牌18', '捨牌19', '捨牌2', '捨牌20', '捨牌3', '捨牌4', '捨牌5', '捨牌6', '捨牌7', '捨牌8', '捨牌9']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1468152, number of negative: 32705640\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 4.307016 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1390\n",
      "[LightGBM] [Info] Number of data points in the train set: 34173792, number of used features: 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hahho\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "c:\\users\\hahho\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.042961 -> initscore=-3.103543\n",
      "[LightGBM] [Info] Start training from score -3.103543\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\tvalid_0's binary_logloss: 0.161273\n",
      "[40]\tvalid_0's binary_logloss: 0.160097\n",
      "[60]\tvalid_0's binary_logloss: 0.159976\n",
      "[80]\tvalid_0's binary_logloss: 0.160117\n",
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's binary_logloss: 0.159966\n",
      "[LightGBM] [Info] Number of positive: 1901658, number of negative: 32272134\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 3.929582 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1390\n",
      "[LightGBM] [Info] Number of data points in the train set: 34173792, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.055647 -> initscore=-2.831478\n",
      "[LightGBM] [Info] Start training from score -2.831478\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\tvalid_0's binary_logloss: 0.201109\n",
      "[40]\tvalid_0's binary_logloss: 0.199633\n",
      "[60]\tvalid_0's binary_logloss: 0.199478\n",
      "[80]\tvalid_0's binary_logloss: 0.199435\n",
      "[100]\tvalid_0's binary_logloss: 0.199422\n",
      "[120]\tvalid_0's binary_logloss: 0.199414\n",
      "[140]\tvalid_0's binary_logloss: 0.199421\n",
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's binary_logloss: 0.19941\n",
      "[LightGBM] [Info] Number of positive: 2246130, number of negative: 31927662\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 3.782368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1390\n",
      "[LightGBM] [Info] Number of data points in the train set: 34173792, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.065727 -> initscore=-2.654264\n",
      "[LightGBM] [Info] Start training from score -2.654264\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\tvalid_0's binary_logloss: 0.230196\n",
      "[40]\tvalid_0's binary_logloss: 0.228897\n",
      "[60]\tvalid_0's binary_logloss: 0.228743\n",
      "[80]\tvalid_0's binary_logloss: 0.228736\n",
      "[100]\tvalid_0's binary_logloss: 0.228714\n",
      "[120]\tvalid_0's binary_logloss: 0.228737\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's binary_logloss: 0.228707\n",
      "[LightGBM] [Info] Number of positive: 2769546, number of negative: 31404246\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 3.701914 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1390\n",
      "[LightGBM] [Info] Number of data points in the train set: 34173792, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081043 -> initscore=-2.428260\n",
      "[LightGBM] [Info] Start training from score -2.428260\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\tvalid_0's binary_logloss: 0.265718\n",
      "[40]\tvalid_0's binary_logloss: 0.263981\n",
      "[60]\tvalid_0's binary_logloss: 0.263706\n",
      "[80]\tvalid_0's binary_logloss: 0.263671\n",
      "[100]\tvalid_0's binary_logloss: 0.26377\n",
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's binary_logloss: 0.263663\n",
      "[LightGBM] [Info] Number of positive: 2837988, number of negative: 31335804\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 3.672433 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1390\n",
      "[LightGBM] [Info] Number of data points in the train set: 34173792, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.083046 -> initscore=-2.401666\n",
      "[LightGBM] [Info] Start training from score -2.401666\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\tvalid_0's binary_logloss: 0.270293\n",
      "[40]\tvalid_0's binary_logloss: 0.268681\n",
      "[60]\tvalid_0's binary_logloss: 0.268462\n",
      "[80]\tvalid_0's binary_logloss: 0.268393\n",
      "[100]\tvalid_0's binary_logloss: 0.268316\n",
      "[120]\tvalid_0's binary_logloss: 0.268277\n",
      "[140]\tvalid_0's binary_logloss: 0.268295\n",
      "Early stopping, best iteration is:\n",
      "[126]\tvalid_0's binary_logloss: 0.268267\n",
      "[LightGBM] [Info] Number of positive: 2784204, number of negative: 31389588\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 4.347614 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1390\n",
      "[LightGBM] [Info] Number of data points in the train set: 34173792, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081472 -> initscore=-2.422514\n",
      "[LightGBM] [Info] Start training from score -2.422514\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\tvalid_0's binary_logloss: 0.26475\n",
      "[40]\tvalid_0's binary_logloss: 0.263098\n",
      "[60]\tvalid_0's binary_logloss: 0.262852\n",
      "[80]\tvalid_0's binary_logloss: 0.262762\n",
      "[100]\tvalid_0's binary_logloss: 0.262699\n",
      "[120]\tvalid_0's binary_logloss: 0.262679\n",
      "[140]\tvalid_0's binary_logloss: 0.262679\n",
      "[160]\tvalid_0's binary_logloss: 0.262663\n",
      "[180]\tvalid_0's binary_logloss: 0.26267\n",
      "Early stopping, best iteration is:\n",
      "[170]\tvalid_0's binary_logloss: 0.262659\n",
      "[LightGBM] [Info] Number of positive: 2245764, number of negative: 31928028\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 3.697710 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1390\n",
      "[LightGBM] [Info] Number of data points in the train set: 34173792, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.065716 -> initscore=-2.654438\n",
      "[LightGBM] [Info] Start training from score -2.654438\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\tvalid_0's binary_logloss: 0.231515\n",
      "[40]\tvalid_0's binary_logloss: 0.2302\n",
      "[60]\tvalid_0's binary_logloss: 0.230051\n",
      "[80]\tvalid_0's binary_logloss: 0.229998\n",
      "[100]\tvalid_0's binary_logloss: 0.22998\n",
      "[120]\tvalid_0's binary_logloss: 0.229956\n",
      "[140]\tvalid_0's binary_logloss: 0.229935\n",
      "[160]\tvalid_0's binary_logloss: 0.229925\n",
      "[180]\tvalid_0's binary_logloss: 0.22992\n",
      "[200]\tvalid_0's binary_logloss: 0.229916\n",
      "[220]\tvalid_0's binary_logloss: 0.229925\n",
      "Early stopping, best iteration is:\n",
      "[211]\tvalid_0's binary_logloss: 0.229915\n",
      "[LightGBM] [Info] Number of positive: 1919838, number of negative: 32253954\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 4.165569 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1390\n",
      "[LightGBM] [Info] Number of data points in the train set: 34173792, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.056179 -> initscore=-2.821400\n",
      "[LightGBM] [Info] Start training from score -2.821400\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\tvalid_0's binary_logloss: 0.198506\n",
      "[40]\tvalid_0's binary_logloss: 0.197198\n",
      "[60]\tvalid_0's binary_logloss: 0.1971\n",
      "[80]\tvalid_0's binary_logloss: 0.197067\n",
      "[100]\tvalid_0's binary_logloss: 0.197074\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's binary_logloss: 0.19706\n",
      "[LightGBM] [Info] Number of positive: 1481598, number of negative: 32692194\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 3.707605 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1390\n",
      "[LightGBM] [Info] Number of data points in the train set: 34173792, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.043355 -> initscore=-3.094015\n",
      "[LightGBM] [Info] Start training from score -3.094015\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\tvalid_0's binary_logloss: 0.161306\n",
      "[40]\tvalid_0's binary_logloss: 0.160033\n",
      "[60]\tvalid_0's binary_logloss: 0.15994\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's binary_logloss: 0.159917\n",
      "[LightGBM] [Info] Number of positive: 377766, number of negative: 33796026\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 4.270906 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1390\n",
      "[LightGBM] [Info] Number of data points in the train set: 34173792, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.011054 -> initscore=-4.493824\n",
      "[LightGBM] [Info] Start training from score -4.493824\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\tvalid_0's binary_logloss: 0.0539575\n",
      "[40]\tvalid_0's binary_logloss: 0.0534836\n",
      "[60]\tvalid_0's binary_logloss: 0.054035\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's binary_logloss: 0.0534685\n",
      "[LightGBM] [Info] Number of positive: 373770, number of negative: 33800022\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 4.178606 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1390\n",
      "[LightGBM] [Info] Number of data points in the train set: 34173792, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.010937 -> initscore=-4.504576\n",
      "[LightGBM] [Info] Start training from score -4.504576\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\tvalid_0's binary_logloss: 0.0560818\n",
      "[40]\tvalid_0's binary_logloss: 0.0556067\n",
      "[60]\tvalid_0's binary_logloss: 0.0563007\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's binary_logloss: 0.0555958\n",
      "[LightGBM] [Info] Number of positive: 359442, number of negative: 33814350\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 4.548896 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1390\n",
      "[LightGBM] [Info] Number of data points in the train set: 34173792, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.010518 -> initscore=-4.544088\n",
      "[LightGBM] [Info] Start training from score -4.544088\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\tvalid_0's binary_logloss: 0.0529839\n",
      "[40]\tvalid_0's binary_logloss: 0.052561\n",
      "[60]\tvalid_0's binary_logloss: 0.0546142\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's binary_logloss: 0.052546\n",
      "[LightGBM] [Info] Number of positive: 356670, number of negative: 33817122\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 4.200164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1390\n",
      "[LightGBM] [Info] Number of data points in the train set: 34173792, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.010437 -> initscore=-4.551912\n",
      "[LightGBM] [Info] Start training from score -4.551912\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\tvalid_0's binary_logloss: 0.0531467\n",
      "[40]\tvalid_0's binary_logloss: 0.0526942\n",
      "[60]\tvalid_0's binary_logloss: 0.0534397\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's binary_logloss: 0.0526609\n",
      "[LightGBM] [Info] Number of positive: 408546, number of negative: 33765246\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 4.353224 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1390\n",
      "[LightGBM] [Info] Number of data points in the train set: 34173792, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.011955 -> initscore=-4.414583\n",
      "[LightGBM] [Info] Start training from score -4.414583\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\tvalid_0's binary_logloss: 0.0585306\n",
      "[40]\tvalid_0's binary_logloss: 0.0578999\n",
      "[60]\tvalid_0's binary_logloss: 0.0578312\n",
      "[80]\tvalid_0's binary_logloss: 0.0582016\n",
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's binary_logloss: 0.0578292\n"
     ]
    }
   ],
   "source": [
    "def helper(n):\n",
    "    k = n//50\n",
    "    r = 0.1 / (k+1)\n",
    "    return r\n",
    "train_and_save('data/both', early_stopping_rounds=20, num_boost_round=1000, learning_rates=helper, verbose_eval=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36e2799b-84e6-40d4-a0cd-fea979463ec8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1468152, number of negative: 32705640\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 4.288985 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1390\n",
      "[LightGBM] [Info] Number of data points in the train set: 34173792, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.042961 -> initscore=-3.103543\n",
      "[LightGBM] [Info] Start training from score -3.103543\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\tvalid_0's binary_logloss: 0.160574\n",
      "[40]\tvalid_0's binary_logloss: 0.160003\n",
      "[60]\tvalid_0's binary_logloss: 0.159957\n",
      "[80]\tvalid_0's binary_logloss: 0.159954\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's binary_logloss: 0.159946\n",
      "[LightGBM] [Info] Number of positive: 1901658, number of negative: 32272134\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 4.637094 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1390\n",
      "[LightGBM] [Info] Number of data points in the train set: 34173792, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.055647 -> initscore=-2.831478\n",
      "[LightGBM] [Info] Start training from score -2.831478\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\tvalid_0's binary_logloss: 0.200314\n",
      "[40]\tvalid_0's binary_logloss: 0.199578\n",
      "[60]\tvalid_0's binary_logloss: 0.199469\n",
      "[80]\tvalid_0's binary_logloss: 0.199436\n",
      "[100]\tvalid_0's binary_logloss: 0.199417\n",
      "[120]\tvalid_0's binary_logloss: 0.199425\n",
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's binary_logloss: 0.199407\n",
      "[LightGBM] [Info] Number of positive: 2246130, number of negative: 31927662\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 4.511029 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1390\n",
      "[LightGBM] [Info] Number of data points in the train set: 34173792, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.065727 -> initscore=-2.654264\n",
      "[LightGBM] [Info] Start training from score -2.654264\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\tvalid_0's binary_logloss: 0.229527\n",
      "[40]\tvalid_0's binary_logloss: 0.22887\n",
      "[60]\tvalid_0's binary_logloss: 0.228773\n",
      "[80]\tvalid_0's binary_logloss: 0.228731\n",
      "[100]\tvalid_0's binary_logloss: 0.228742\n",
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's binary_logloss: 0.228726\n",
      "[LightGBM] [Info] Number of positive: 2769546, number of negative: 31404246\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 4.411156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1390\n",
      "[LightGBM] [Info] Number of data points in the train set: 34173792, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081043 -> initscore=-2.428260\n",
      "[LightGBM] [Info] Start training from score -2.428260\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\tvalid_0's binary_logloss: 0.264819\n",
      "[40]\tvalid_0's binary_logloss: 0.263901\n",
      "[60]\tvalid_0's binary_logloss: 0.26376\n",
      "[80]\tvalid_0's binary_logloss: 0.26373\n",
      "[100]\tvalid_0's binary_logloss: 0.26376\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's binary_logloss: 0.26373\n",
      "[LightGBM] [Info] Number of positive: 2837988, number of negative: 31335804\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 4.351713 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1390\n",
      "[LightGBM] [Info] Number of data points in the train set: 34173792, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.083046 -> initscore=-2.401666\n",
      "[LightGBM] [Info] Start training from score -2.401666\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\tvalid_0's binary_logloss: 0.269495\n",
      "[40]\tvalid_0's binary_logloss: 0.268589\n",
      "[60]\tvalid_0's binary_logloss: 0.268448\n",
      "[80]\tvalid_0's binary_logloss: 0.268363\n",
      "[100]\tvalid_0's binary_logloss: 0.268321\n",
      "[120]\tvalid_0's binary_logloss: 0.268294\n",
      "[140]\tvalid_0's binary_logloss: 0.26828\n",
      "[160]\tvalid_0's binary_logloss: 0.268269\n",
      "[180]\tvalid_0's binary_logloss: 0.268251\n",
      "[200]\tvalid_0's binary_logloss: 0.268237\n",
      "[220]\tvalid_0's binary_logloss: 0.268227\n",
      "[240]\tvalid_0's binary_logloss: 0.268219\n",
      "[260]\tvalid_0's binary_logloss: 0.268213\n",
      "[280]\tvalid_0's binary_logloss: 0.268204\n",
      "[300]\tvalid_0's binary_logloss: 0.268199\n",
      "[320]\tvalid_0's binary_logloss: 0.268195\n",
      "[340]\tvalid_0's binary_logloss: 0.268192\n",
      "[360]\tvalid_0's binary_logloss: 0.268188\n",
      "[380]\tvalid_0's binary_logloss: 0.268186\n",
      "[400]\tvalid_0's binary_logloss: 0.268183\n",
      "[420]\tvalid_0's binary_logloss: 0.268181\n",
      "[440]\tvalid_0's binary_logloss: 0.268179\n",
      "[460]\tvalid_0's binary_logloss: 0.268176\n",
      "[480]\tvalid_0's binary_logloss: 0.268174\n",
      "[500]\tvalid_0's binary_logloss: 0.268172\n",
      "[520]\tvalid_0's binary_logloss: 0.268171\n",
      "[540]\tvalid_0's binary_logloss: 0.268169\n",
      "[560]\tvalid_0's binary_logloss: 0.268167\n",
      "[580]\tvalid_0's binary_logloss: 0.268166\n",
      "[600]\tvalid_0's binary_logloss: 0.268165\n",
      "[620]\tvalid_0's binary_logloss: 0.268163\n",
      "[640]\tvalid_0's binary_logloss: 0.268162\n",
      "[660]\tvalid_0's binary_logloss: 0.268162\n",
      "[680]\tvalid_0's binary_logloss: 0.268161\n",
      "[700]\tvalid_0's binary_logloss: 0.26816\n",
      "Early stopping, best iteration is:\n",
      "[689]\tvalid_0's binary_logloss: 0.26816\n",
      "[LightGBM] [Info] Number of positive: 2784204, number of negative: 31389588\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 4.741235 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1390\n",
      "[LightGBM] [Info] Number of data points in the train set: 34173792, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081472 -> initscore=-2.422514\n",
      "[LightGBM] [Info] Start training from score -2.422514\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\tvalid_0's binary_logloss: 0.263906\n",
      "[40]\tvalid_0's binary_logloss: 0.262957\n",
      "[60]\tvalid_0's binary_logloss: 0.262833\n",
      "[80]\tvalid_0's binary_logloss: 0.262754\n",
      "[100]\tvalid_0's binary_logloss: 0.26276\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's binary_logloss: 0.262742\n",
      "[LightGBM] [Info] Number of positive: 2245764, number of negative: 31928028\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 4.706923 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1390\n",
      "[LightGBM] [Info] Number of data points in the train set: 34173792, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.065716 -> initscore=-2.654438\n",
      "[LightGBM] [Info] Start training from score -2.654438\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\tvalid_0's binary_logloss: 0.230812\n",
      "[40]\tvalid_0's binary_logloss: 0.23013\n",
      "[60]\tvalid_0's binary_logloss: 0.230009\n",
      "[80]\tvalid_0's binary_logloss: 0.229975\n",
      "[100]\tvalid_0's binary_logloss: 0.229941\n",
      "[120]\tvalid_0's binary_logloss: 0.229966\n",
      "Early stopping, best iteration is:\n",
      "[116]\tvalid_0's binary_logloss: 0.229931\n",
      "[LightGBM] [Info] Number of positive: 1919838, number of negative: 32253954\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 4.426785 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1390\n",
      "[LightGBM] [Info] Number of data points in the train set: 34173792, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.056179 -> initscore=-2.821400\n",
      "[LightGBM] [Info] Start training from score -2.821400\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\tvalid_0's binary_logloss: 0.197795\n",
      "[40]\tvalid_0's binary_logloss: 0.197162\n",
      "[60]\tvalid_0's binary_logloss: 0.197166\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's binary_logloss: 0.19712\n",
      "[LightGBM] [Info] Number of positive: 1481598, number of negative: 32692194\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 4.552103 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1390\n",
      "[LightGBM] [Info] Number of data points in the train set: 34173792, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.043355 -> initscore=-3.094015\n",
      "[LightGBM] [Info] Start training from score -3.094015\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\tvalid_0's binary_logloss: 0.160588\n",
      "[40]\tvalid_0's binary_logloss: 0.159962\n",
      "[60]\tvalid_0's binary_logloss: 0.159877\n",
      "[80]\tvalid_0's binary_logloss: 0.159934\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's binary_logloss: 0.159874\n",
      "[LightGBM] [Info] Number of positive: 377766, number of negative: 33796026\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 4.213469 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1390\n",
      "[LightGBM] [Info] Number of data points in the train set: 34173792, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.011054 -> initscore=-4.493824\n",
      "[LightGBM] [Info] Start training from score -4.493824\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\tvalid_0's binary_logloss: 0.0537413\n",
      "[40]\tvalid_0's binary_logloss: 0.0536231\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.053483\n",
      "[LightGBM] [Info] Number of positive: 373770, number of negative: 33800022\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 4.011135 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1390\n",
      "[LightGBM] [Info] Number of data points in the train set: 34173792, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.010937 -> initscore=-4.504576\n",
      "[LightGBM] [Info] Start training from score -4.504576\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\tvalid_0's binary_logloss: 0.055914\n",
      "[40]\tvalid_0's binary_logloss: 0.0558777\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's binary_logloss: 0.055678\n",
      "[LightGBM] [Info] Number of positive: 359442, number of negative: 33814350\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 5.522829 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1390\n",
      "[LightGBM] [Info] Number of data points in the train set: 34173792, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.010518 -> initscore=-4.544088\n",
      "[LightGBM] [Info] Start training from score -4.544088\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\tvalid_0's binary_logloss: 0.0528433\n",
      "[40]\tvalid_0's binary_logloss: 0.0533718\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's binary_logloss: 0.0526533\n",
      "[LightGBM] [Info] Number of positive: 356670, number of negative: 33817122\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 3.827582 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1390\n",
      "[LightGBM] [Info] Number of data points in the train set: 34173792, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.010437 -> initscore=-4.551912\n",
      "[LightGBM] [Info] Start training from score -4.551912\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\tvalid_0's binary_logloss: 0.0529286\n",
      "[40]\tvalid_0's binary_logloss: 0.0531193\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's binary_logloss: 0.0527425\n",
      "[LightGBM] [Info] Number of positive: 408546, number of negative: 33765246\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 4.318318 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1390\n",
      "[LightGBM] [Info] Number of data points in the train set: 34173792, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.011955 -> initscore=-4.414583\n",
      "[LightGBM] [Info] Start training from score -4.414583\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\tvalid_0's binary_logloss: 0.0581964\n",
      "[40]\tvalid_0's binary_logloss: 0.0578512\n",
      "[60]\tvalid_0's binary_logloss: 0.0579588\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's binary_logloss: 0.0578223\n"
     ]
    }
   ],
   "source": [
    "def helper(n):\n",
    "    k = n//30\n",
    "    r = 0.13 / (k+1)\n",
    "    return r\n",
    "train_and_save('data/both', early_stopping_rounds=20, num_boost_round=1000, learning_rates=helper, verbose_eval=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c44df0-9d09-43a8-ba9e-8d8bb11513ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper(n):\n",
    "    k = n//40\n",
    "    r = 0.075 / (k+1)\n",
    "    return r\n",
    "train_and_save('data/both', early_stopping_rounds=20, num_boost_round=1000, learning_rates=helper, verbose_eval=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d46c0a7-d437-44e0-b9ca-836d7766fd83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
